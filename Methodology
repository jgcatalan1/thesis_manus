MATERIALS AND METHODS

System Design and Architecture
This study employed a comprehensive system design approach that integrated machine learning capabilities with mobile application development to deliver an accessible yield prediction tool for rice farmers. The system architecture was designed to function offline, ensuring usability in areas with limited internet connectivity while maintaining computational efficiency on mobile devices. The design framework encompassed data collection, model development, mobile application integration, and user interaction components that worked together to provide accurate yield predictions based on agronomic inputs.
As shown in Fig. 16, the conceptual framework demonstrates the interconnected relationship between farmers as end-users, data collection processes, machine learning algorithms, and mobile application interfaces. This framework serves as the foundation for understanding how agronomic data flows through the system to generate actionable yield predictions that support farmer decision-making in rice production.
 
Fig. 16. Conceptual framework of the study
The system architecture followed a three-tier design pattern, consisting of the presentation layer (mobile user interface), business logic layer (data processing and Random Forest model), and data persistence layer (local storage for farmer inputs and prediction results). This modular approach ensured scalability, maintainability, and efficient resource utilization on mobile devices while providing seamless user experience for farmers with varying levels of technological expertise.
The technology stack integrated Python-based machine learning development with Kotlin-based Android application development, utilizing the m2cgen library for model conversion and ensuring compatibility across the development and deployment phases.  
Development Methodology Framework
This study adopted the Rapid Application Development (RAD) model as the primary software development methodology for creating the GabayPalay mobile application. The RAD model was selected due to its iterative approach, emphasis on user feedback, and capability to accommodate evolving requirements throughout the development process.
As illustrated in Fig. 17, the RAD model consists of four phases: Requirements Planning, User Design, Construction, and Cutover. This methodology provided a systematic framework for developing the mobile application from initial user requirements to final deployment and evaluation. Each phase incorporated continuous testing and validation to ensure that both technical functionality and user experience requirements were met throughout the development lifecycle. The implementation of this methodology required careful attention to research ethics and participant protection, particularly given the involvement of rice farmers in various stages of the development process.
 
Fig. 17. Rapid Application Development Model lifted from Dennis (2023).
Ethical considerations
All participants in this study were thoroughly informed about the nature, objectives, and procedures of the research prior to their involvement. Only individuals aged 18 to 59 years old were included, ensuring that all participants were legally capable of giving informed consent. Participation was completely voluntary, and participants were free to withdraw from the study at any time without penalty or consequence.
No personally identifiable information was collected, and all responses were kept strictly confidential. Data was anonymized during analysis and reporting to safeguard participants’ privacy. The instruments and procedures used in this study were designed to minimize any potential discomfort, risk, or burden to participants.
Prior to any data collection, the informed consent form (see Appendix 1) was provided and explained to each participant, ensuring that they understood their rights and the study’s procedures. Throughout the entire research process, ethical standards were upheld to guarantee the responsible and respectful treatment of all individuals involved.
Phase 1: Requirements Planning
The requirements planning phase constituted the foundational stage of the RAD methodology, focusing on comprehensive stakeholder analysis, user research, and systematic requirements identification to establish both functional and technical specifications for the GabayPalay mobile application. This phase employed a mixed-method research approach to gather comprehensive data about rice farming practices, technology adoption patterns, and user needs in Hagonoy, Davao del Sur.
Mixed-method research design
The requirements planning phase implemented an exploratory sequential mixed-method design, as described by Creswell and Creswell (2018) which combined qualitative interviews with quantitative surveys to establish a comprehensive understanding of user requirements and technical specifications (Fig. 18). This approach enabled the collection of both in-depth qualitative insights about farming practices and quantifiable data about agronomic variables that influence rice yield outcomes.
The qualitative component involved face-to-face interviews with rice farmers to explore current farming practices, technology adoption barriers, and specific feature requirements for the mobile application. To ensure the validity of the findings, the results of these interviews were reviewed and validated by rice farming experts. The quantitative phase employed structured surveys to collect numerical data on farming parameters, yield outcomes, and technology usage patterns among the target user population.
Stakeholder analysis and user research
A comprehensive stakeholder analysis was conducted to identify key participants in the rice farming environment of Hagonoy, Davao del Sur. Primary stakeholders included rice farmers who represented the core user base for the mobile application, while secondary stakeholders encompassed agricultural extension workers, local government units, and rice production support organizations.
 
Fig. 18. Exploratory sequential mixed-method design integrating qualitative interviews and quantitative surveys for requirements planning. 
The user research component employed purposive sampling to select 5 to 15 participants, ensuring diverse representation of farm sizes, experience levels, and technological familiarity (Palinkas et al., 2015). This approach facilitated the identification of varying user needs and technology adoption patterns across different farmer demographics within the target municipality.
Guide questionnaires for interviews focused on three key areas: current farming practices, mobile application usage patterns, and improvement factors for rice productivity. The interview protocol addressed methods for land preparation, seeding, fertilization, and pest control, as well as decision-making processes for input quantities and farming cycle challenges.
Data collection framework
The data collection framework established a systematic approach for gathering comprehensive agronomic data from rice farmers in Hagonoy, Davao del Sur. The framework integrated both structured survey instruments and standardized data collection protocols to ensure consistency and reliability across all data gathering activities.
 
Fig. 19. Data collection framework illustrating the sampling approach, administration of structured face-to-face surveys, integration of qualitative and quantitative variables, and standardized protocols for consistency and reliability in agronomic data gathering.
Illustrated in Fig. 19, the data collection employed a non-probability quota sampling approach, with respondents selected based on accessibility and willingness to participate. The surveys were administered through face-to-face interviews to maximize accuracy and minimize item non-response, following the methodology described by Lavrakas (2011). This approach ensured high-quality data collection while accommodating the diverse technological backgrounds of participating farmers.
The data collection instrument captured essential farming information including land area, seed usage rates, fertilizer applications (N-P-K), pesticide usage patterns, and corresponding yield outcomes. Additional variables identified during the qualitative phase were systematically integrated to enhance the comprehensiveness of the dataset.
Technology adoption assessment
The technology adoption assessment examined existing mobile application usage patterns among rice farmers, building on findings (in Table 2) from Angchay et al. (2024) who identified that farmers in Davao del Sur use various agricultural applications including Accuweather, SpidTech, and Rice Doctor apps. However, barriers such as digital literacy gaps and connectivity issues were recognized as significant challenges to technology adoption (Gabrillo and Torres, 2022).
This assessment evaluated current technology usage, identified barriers to mobile application adoption, and determined farmer preferences for application features and functionality. The evaluation considered factors such as device compatibility, offline functionality requirements, and interface design preferences suitable for users with varying technological backgrounds.
Requirements identification framework
Requirements identification followed a systematic approach combining interview data analysis with quantitative survey findings to establish comprehensive system specifications. The methodology addressed both functional requirements (what the system should do) and non-functional requirements (how the system should perform) for the GabayPalay mobile application.
Interview data (guide questionnaire found in Appendix 2) was analyzed using thematic analysis to identify common patterns in farming practices, technological needs, and user preferences. Survey data (survey instrument form found in Appendix 3) provided quantitative validation of key agronomic variables and usage patterns identified during the qualitative phase.
Functional and non-functional requirements specification
Functional requirements were derived from user research findings and focused on core application capabilities including offline rice yield prediction, agronomic data input processing, result visualization, and local data storage functionality. The system was designed to accept user inputs for key variables including land area, seed rate, fertilizer applications (N, P, K), pest occurrence and pesticide usage. 
Non-functional requirements addressed system performance, usability, and compatibility constraints. Minimum device specifications included Android 8.0 (Oreo) or higher, at least 2GB RAM, and 16GB internal storage to ensure broad accessibility among the target user population. The system was designed for offline operation to address connectivity limitations identified in rural farming areas. 
User interface requirements emphasize simplicity and accessibility for farmers with varying technological backgrounds. The application design incorporated intuitive navigation, clear data input forms, and comprehensible result presentation to minimize learning requirements and maximize usability.
Phase 2: Data Processing and Model Development
The data processing and model development phase constituted the core technical component of the RAD methodology, focusing on systematic data collection, preprocessing, and machine learning model implementation. This phase transformed the requirements identified in Phase 1 into a functional Random Forest regression model capable of predicting rice yield based on agronomic input variables.
Data preprocessing pipeline
A systematic preprocessing procedure was implemented using Python's core data processing libraries, including pandas for data manipulation, NumPy for numerical operations, and scikit-learn for machine learning preprocessing tasks. The preprocessing pipeline addressed data quality issues, standardized variable formats, and prepared the dataset for machine learning analysis.
Preprocessing focused on the agronomic input variables defined in Table 5 including land area, rice variety, amount of seed used, planting method, land preparation methods, irrigation source, fertilizer applications, pest incidence, pesticide and chemical usage, weather-related challenges, and palay yield. Data cleaning procedures included outlier detection, missing value imputation, and data type standardization to ensure consistency across all variables.
For fertilizer application variables (X9-X17), all entries were mathematically standardized based on the NPK ratio declared on the fertilizer label. Fertilizers such as urea, potash, complete, and other products are typically reported by farmers according to their NPK ratio representing the percentage of nitrogen (N), phosphorus (as P₂O₅), and potassium (as K₂O), rather than by elemental composition. Standardizing these variables serves to consolidate the nutrient information, preventing the dataset from expanding with multiple features for each fertilizer brand or formulation. This approach ensures that, for each split or application, only one feature each for N, P, and K is maintained, thereby simplifying the dataset and supporting robust analysis. The amount of each nutrient supplied per application was computed as follows: 
Nitrogen\ (N)\ supplied\ (kg)\ =\ x\ \times\ \left(\frac{a}{100}\right)	[7]

Phosphorus\ (P)\ supplied\ as\ P₂O₅ (kg) = x × b100
[8]

Potassium\ (K)\ supplied\ as\ K₂O (kg) = x × c100
[9]

where x is the amount of fertilizer applied (in kg) and a:b:c are the NPK percentages indicated on the fertilizer label. This method follows the guidelines of the Department of Agriculture-Agricultural Training Institute – Cordillera Administrative Region (2022).
Table 5. Feature definitions and units for agronomic and management data.
Factor	Description	Unit/Value Type
X1	Land Area	hectares (ha)
X2	Rice Variety	binary (1 = Hybrid, 0 = Inbred)
X3	Amount of Seed used	kilograms (kg)
X4	Planting Method	binary (1 = Transplanted, 0 = Direct Seeding)
X5	Land preparation - Manual	binary (1 = Yes, 0 = No)
X6	Land Preparation - Tractor	binary (1 = Yes, 0 = No)
X7	Land Preparation - Rotavator	binary (1 = Yes, 0 = No)
X8	Water Irrigation Source	binary (1 = Yes, 0 = No)
X9	Total Nitrogen - First Application	kilograms (kg)
X10	Total Phosphorus - First Application	kilograms (kg as P₂O₅)
X11	Total Potassium - First Application	kilograms (kg as K₂O)
X12	Total Nitrogen - Second Application	kilograms (kg)
X13	Total Phosphorus - Second Application	kilograms (kg as P₂O₅)
X14	Total Potassium - Second Application	kilograms (kg as K₂O)
X15	Total Nitrogen - Third Application	kilograms (kg)
X16	Total Phosphorus - Third Application	kilograms (kg as P₂O₅)
X17	Total Potassium - Third Application	kilograms (kg as K₂O)
X18	Pest - Stem Borer	binary (1 = Present, 0 = Absent)
X19	Pest - Rats	binary (1 = Present, 0 = Absent)
X20	Pest - Kuhol	binary (1 = Present, 0 = Absent)
X21	Pest - Cutworms	binary (1 = Present, 0 = Absent)
X22	Pest - Rice Blast	binary (1 = Present, 0 = Absent)
X23	Insecticide	liters (L)
X24	Herbicide	liters (L)
X25	Rat Poison	grams (g)
X26	Molluscicide	sachets
X27	Weather-related challenges	binary (1 = Present, 0 = Absent)
Y	Palay Yield	kilograms (kg)

All preprocessing steps were implemented through modular Python scripts to ensure transparency, reproducibility, and adaptability throughout the data preparation workflow. The complete codebase for these procedures is provided in Appendix 4.

Agronomic variables framework
The agronomic variables framework organizes all input variables according to their corresponding activity stage within the rice production process. This framework was developed based on factors identified in the review of related literature, as summarized in Table 5. 
Each variable was assigned to one of three main categories: Pre-planting, Growth, or Post-Production. This activity-based categorization was adapted from the Step-by-step production - IRRI Rice Knowledge Bank (n.d.). Pre-planting variables include management practices and decisions made before planting, such as land preparation, seed selection, and irrigation setup. Growth variables capture management actions and environmental factors during the crop’s development, including fertilizer applications, pest management, and weather-related challenges. The post-production category includes outcomes such as palay yield.
ML pipeline architecture
Building upon the best practices and pipeline frameworks identified in the RRL, this study adapts a modular machine learning (ML) pipeline architecture for yield prediction, as illustrated in Fig. 13. It emphasizes the importance of systematic data flow, modular design for testing and validation, and the integration of data preprocessing, feature engineering, model training, and prediction components. These foundational concepts form the basis for the workflow implemented in this research.
To address the specific requirements of this study, the pipeline was tailored to ensure consistent handling and traceability of variables from survey collection to final yield prediction. Key components included data validation modules, preprocessing transformers, feature selection algorithms, and a Random Forest regression model, all designed following the modular approach highlighted in related literature. The architecture was further customized to support both batch processing for model training and real-time inference for deployment in a mobile application, with additional modifications to enable offline functionality. This ensures that prediction services remain accessible even in the absence of internet connectivity.
Random forest implementation and optimization
The Random Forest regression model was implemented using Python’s scikit-learn library. The model utilized bootstrap aggregating (bagging) and feature randomization techniques to improve prediction accuracy and reduce overfitting compared to individual decision trees.
The mathematical foundation of the Random Forest regressor was expressed as the average of individual tree predictions (Equation [10]):
\hat{y}=\frac{1}{T}\sum_{t=1}^{\ T}{h_t(X)}	[10]

where T represents the total number of decision trees, h_t\left(X\right)\ denotes the prediction from the t-th tree for input X, and  \hat{y} represents the estimated rice yield.

Hyperparameter optimization employed grid search methodology to determine optimal values for key parameters including the number of trees (n_estimators), maximum tree depth (max_depth), minimum samples for node splitting (min_samples_split), and minimum samples per leaf (min_samples_leaf). The optimization process utilized cross-validation to ensure robust parameter selection and prevent overfitting to the training dataset.
The hyperparameter search space, shown in Table 6, was defined based on established Random Forest tuning guidelines and empirical practices in agricultural yield prediction, balancing model complexity, computational efficiency, and overfitting risk for small agricultural datasets typical of single-municipality studies.
The number of trees (n_estimators) was explored across [100, 200, 300, 400]. Breiman (2001) demonstrated that Random Forest performance typically stabilizes after 100-200 trees, while Probst et al. (2019) recommended values between 100-500 for small to moderate datasets, noting that larger ensembles improve stability but increase computational cost. Agricultural studies have employed similar ranges: Jeong et al. (2016) used 100-500 trees for crop yield prediction, finding optimal performance at 200-300 trees, while Khaki and Wang (2019) reported comparable results. The upper limit of 400 trees accommodated mobile deployment constraints, where model conversion to Java for Android integration and device memory limitations necessitated balancing ensemble size against computational feasibility. Maximum tree depth (max_depth) was evaluated at [None, 10, 20], representing unrestricted growth, moderate depth, and shallow trees. Probst et al. (2019) noted that unrestricted depth allows full pattern capture but increases overfitting risk in small datasets, while depth constraints provide explicit regularization. Hastie et al. (2009) recommended depth limits proportional to log₂(n) for small samples, suggesting moderate depths (5-15) are often appropriate, though practical implementations may use higher values (10-20) to capture non-linear interactions. This aligned with agricultural applications: Jeong et al. (2016) evaluated depths of 5-15 for crop yield models, while Ji et al. (2021) found optimal performance at max_depth=10 for rice yield prediction with comparable dataset sizes.
The minimum samples required to split an internal node (min_samples_split) was varied across [2, 4, 6], with the default value of 2 permitting maximum flexibility while higher values reduce variance at the cost of potential underfitting (Hastie et al., 2009). Probst et al. (2019) recommended exploring values from the default up to approximately 5-10% of training set size for small datasets. Similarly, minimum samples at leaf nodes (min_samples_leaf) was tested at [1, 2, 3], representing low-single-digit values appropriate for datasets with fewer than 100 observations (Probst et al., 2019). The number of features at each split (max_features) was limited to ['sqrt', 'log2'], corresponding to √p and log₂(p) features (p=27). Breiman (2001) originally recommended √p for classification and p/3 for regression, though subsequent work showed that 'sqrt' and 'log2' perform comparably while providing substantial feature randomization (Hastie et al., 2009; Probst et al., 2019). The exclusion of max_features='None' was deliberate, as using all features reduces tree diversity and increases overfitting risk (Breiman, 2001). Agricultural applications have similarly favored 'sqrt' and 'log2' (Jeong et al., 2016; Prasath et al., 2023). The grid search evaluated all 216 unique combinations (4\times3\times3\times3\times2) using 3-fold cross-validation, with performance assessed via R². This exhaustive approach ensured systematic exploration without reliance on heuristic methods that might converge to local optima (Bergstra & Bengio, 2012).
Table 6. Hyperparameter search space for Random Forest grid search optimization
Hyperparameter	Values Tested
n_estimators	[100, 200, 300, 400]
max_depth	[None, 10, 20]
min_samples_split	[2, 4, 6]
min_samples_leaf	[1, 2, 3]
max_features	['sqrt', 'log2']
Total combinations	216
Model validation and performance metrics
Model validation employed 3-fold cross-validation (k=3) to assess generalization performance during hyperparameter tuning while accounting for the limited dataset size typical of localized agricultural studies. The selection of k=3 was motivated by training set size, validation fold representativeness, and computational efficiency (James et al., 2023b). 
For small agricultural datasets (n<100) with a 70/30 train-test split, 3-fold cross-validation provides a reasonable balance between training set size and validation set size for performance estimation. James et al. (2013) note that the choice of k involves a bias-variance trade-off: smaller k values (k=[2,3]) produce higher bias but lower variance in performance estimates, while larger k values (k=10) reduce bias but increase variance, particularly when datasets are small. For n<50 observations, James et al. (2013) recommend k=3 or k=5 to avoid excessively small training folds that compromise model fitting. The use of k=3 rather than k=10 was further justified by the need to maintain adequately sized validation folds relative to model complexity: with 27 input features and a Random Forest ensemble requiring sufficient samples per tree for stable splits, smaller k values ensure each validation fold contains enough observations for reliable performance estimation. Varoquaux et al. (2017) demonstrated that for small sample sizes (n=[20,100])), k=3 cross-validation produced more stable performance estimates than k=10, as smaller k values reduced the impact of individual outliers on fold composition. This principle applies directly to agricultural datasets where farm-level heterogeneity can produce high variance in small validation folds. Agricultural yield prediction studies with comparable dataset sizes have similarly employed k=3 or k=5: Ji et al. (2021) employed 3-fold cross-validation for rice yield modeling with approximately 80 observations, while David (2023) employed train-test splitting due to dataset constraints. Additionally, computational efficiency supported k=3: grid search evaluated 216 hyperparameter combinations, each requiring k training-validation cycles, balancing thorough resampling against computation time. The final model was validated on a held-out test set (30% of total data) never used during training or hyperparameter selection, providing independent assessment of generalization performance (Hastie et al., 2009; Kuhn & Johnson, 2013).
Performance evaluation utilized four standard regression metrics to comprehensively assess model accuracy and reliability. Mean Square Error (MSE) calculated the average squared difference between actual and predicted values (equation [11]):
\mathrm{MSE}=\frac{1}{n}\sum_{i=1}^{n}{\left(y_i-{\hat{y}}_i\right)^2\ }	[11]

Root Mean Square Error (RMSE) provided error measurement in the same units as the dependent variable (equation [12]):
\mathrm{RMSE}=\sqrt{\mathrm{MSE}}	[12]

Mean Absolute Error (MAE) calculated the average absolute differences between actual and predicted values, offering interpretation advantages and reduced sensitivity to outliers (equation [13]):
\mathrm{MAE}=\frac{1}{n}\sum_{i=1}^{n}{\left|y_i-{\hat{y}}_i\right|\ }	[13]

The coefficient of determination (R²) evaluated the proportion of variance in actual yield explained by the model predictions (equation [14]):
R^2=1-\frac{\sum_{i=1}^{n}{\left(y_i-{\hat{y}}_i\right)^2\ }}{\sum_{i=1}^{n}{\left(y_i-\bar{y}\right)^2\ }}	[14]

where n represents the number of samples, y_i denotes actual yield,  {\hat{y}}_i represents predicted yield, and  \bar{y} indicates the mean actual yield (Kuhn and Johnson, 2013).
Model training and validation workflow
The model training and validation workflow, shown in Fig. 20, established a systematic process for developing, testing, and validating the Random Forest regression model while maintaining generalizability to unseen data. The workflow began with splitting the collected dataset at the farm level using a 70-30 ratio, allocating 70 percent for model training and hyperparameter optimization and 30 percent for independent evaluation. Farms in the test set were held out and excluded from all model development procedures to ensure unbiased performance assessment.
 
Fig. 20. Model training and validation workflow. The dataset is split into training and test sets, followed by cross-validation and hyperparameter tuning. 
The training phase employed grid search with three-fold cross-validation to systematically evaluate 216 hyperparameter combinations (n_estimators, max_depth, min_samples_split, min_samples_leaf, and max_features). Each configuration was assessed using the coefficient of determination (R²) as the primary metric, with root mean squared error (RMSE) tracked for interpretability. Cross-validation partitioned the training set into three folds, training each candidate model on approximately two-thirds of the training data and validating on the remaining third, then averaging performance across folds to identify the optimal hyperparameter configuration (random_state=42 for reproducibility). All preprocessing, imputation, and feature engineering were implemented within a scikit-learn Pipeline and fitted separately within each training fold to prevent data leakage.
Following hyperparameter selection, the final Random Forest model was trained on the complete training set using the optimal configuration identified through grid search. This best model was then evaluated once on the held-out test set to confirm generalization performance. Performance evaluation calculated MSE, RMSE, MAE, and R² to comprehensively assess prediction accuracy and model reliability.
Model persistence and deployment preparation completed the workflow. The trained model was exported using the m2cgen library to convert the scikit-learn Random Forest implementation into standalone Java code, enabling offline inference in the Android mobile application without external dependencies. This conversion process maintained perfect numerical parity with the Python model, ensuring consistent prediction performance across development and production environments. The complete model training and export code is provided in Appendix 5.
Phase 3: User Design and System Architecture
The user design and system architecture phase focused on translating functional requirements and model specifications into a comprehensive mobile application design. This phase established the architectural foundation, user interface design principles, and system interaction workflows necessary for delivering an intuitive and effective rice yield prediction tool for farmers in Hagonoy, Davao del Sur. 
Mobile application architecture 
The GabayPalay mobile application employs a layered modular architecture, reflecting established best practices in Android development (Android Developers, 2025). This architectural approach enables clear separation of concerns, promotes maintainability, and facilitates scalability as the application evolves. As illustrated in Fig. 21, each layer of architecture is assigned distinct responsibilities, which collectively streamline development and support future enhancements.
At the foundation is the data and model layer, which is tasked with core processes such as data storage, validation, and execution of yield prediction algorithms. By isolating business logic within this layer, the application allows for updates and testing of computational models without impacting the user interface or user experience.
 
Fig. 21. Layered Modular Architecture of the GabayPalay Mobile Application, showing the separation of User Interface, Business Logic, and Data/Model layers.
 
Fig. 22. Context Diagram (DFD Level 0) of the GabayPalay Application.
The user interface (UI) layer encompasses all visual and interactive elements, including data entry forms, result displays, and navigation components. The UI is purposefully designed to be intuitive and accessible, ensuring usability for farmers with diverse levels of technological familiarity.
The business logic layer bridges the UI and data/model layers, handling user interactions, input validation, error management, and ensuring a consistent experience across Android devices. Layered modular architecture provides a strong foundation for GabayPalay, supporting its maintainability, extensibility, and reliability as new features are added.
Data flow diagram
This section presented the Data Flow Diagrams (DFDs) for the GabayPalay Application, providing a comprehensive illustration of how data traversed the system and elucidating the major processes involved in palay yield prediction and farm management.
The context diagram, shown in Fig. 22, depicted the overall system boundary and highlighted the external interactions of the GabayPalay Application. Within this framework, the Farmer served as the primary external entity, supplying farm data inputs to the system. The application managed data persistence by storing and retrieving relevant information through Local Storage, which ensured access to historical records and supported data continuity. After processing the input data, the application delivered yield predictions and data analytics to the Farmer, thereby facilitating more informed and effective decision-making in the management of farm operations.
Fig. 23 presented the Level 1 Data Flow Diagram, which detailed the internal structure of the GabayPalay Application. The Farmer initiated the process by submitting data related to pre-planting preparation and methods, fertilizer management, pest management, and environmental challenges. Each of these modules was designed to handle specific aspects of farm operations. The data collected from these processes was then forwarded to the Palay Yield Prediction module, which synthesized the inputs to generate a yield prediction. Both farm inputs and prediction results were saved in Local Storage, allowing for future reference and historical tracking. The Yield Prediction History module enabled the Farmer to review past inputs and prediction results, supporting continuous improvement in farming practices. Throughout the process, the Farmer remained involved by viewing all data inputs and system outputs.
Fig. 24 showed the Level 2 Data Flow Diagram for Fertilizer Management, which provided a detailed breakdown of how the Farmer supplied fertilizer management information, beginning with the specification of the number of fertilizer applications or splits throughout the cropping season. After receiving this input, the application prompted the Farmer to select the appropriate fertilizer name and measurement unit, thereby ensuring the accuracy of the data. Based on these selections, the system calculated the total quantities of nitrogen, phosphorus, and potassium applied per split, utilizing the NPK ratio associated with the chosen fertilizer. These computed nutrient values were subsequently stored in Local Storage, which ensured that all fertilizer-related data remained readily available for future yield prediction, analysis, and continuous refinement of farm management practices.
Collectively, these diagrams demonstrated the GabayPalay Application’s systematic, modular, and user-centered design, where data consistently flowed from the Farmer through each process, underwent validation and transformation by the system, and was securely stored for subsequent use. The relationships depicted emphasized the seamless integration of user inputs, process modules, and persistent data storage, resulting in a robust foundation that supported accurate palay yield prediction, comprehensive farm analytics, and the overall enhancement of agricultural decision-making.
 
Fig. 23. Data Flow Diagram (DFD Level 1) showing the Major Functional Modules of the GabayPalay Application.
 
Fig. 24. Data Flow Diagram (DFD Level 2) detailing the Fertilizer Management process of the GabayPalay Application.
Control flow diagram
Fig. 25 presented the control flow diagram developed for the GabayPalay Android-based Mobile Application. This diagram outlined the sequential operations and decision points that structured the application's prediction and data management workflows.
Upon launching the application, users were directed to the Main Page, which served as the central hub for navigation. From this interface, users selected between two core functionalities: Predict Palay Yield and History.
When users opted to predict palay yield, the application guided them through a multi-step input workflow. This process began with the Pre-planting Page, where pre-planting data was entered. Users then proceeded to the Fertilizer Management Page to provide fertilizer amounts and specify the number of applications or splits. The system assessed whether the maximum number of allowable fertilizer splits had been reached, restricting further input if the limit had been attained. Subsequent stages included the input of pesticide amounts and the selection of anticipated pests on the Pest Management Page.  
 
Fig. 25. Control flow diagram (CFD) of the GabayPalay mobile application. Illustrates the sequence of user actions for palay yield prediction, starting from farm data entry and proceeding through input validation and decision points. Includes steps for yield calculation, saving new records, and retrieving stored results. Highlights the main workflow and logic within the application.
 
When users indicated expected weather-related challenges, relevant data were gathered through a dedicated input page. At each stage, the system performed input validation to ensure completeness and logical consistency.
All farm inputs were then reviewed prior to prediction processing. Upon confirmation of complete and valid data, the application executed the palay yield prediction using a Random Forest Regressor model. The results were displayed to the user, who was given the option to save both the prediction and corresponding input data to the local database
For users selecting the History option, the application retrieved all previously saved prediction records from the local database. If historical data were available, these were displayed; otherwise, the system notified the user that "No history has been saved." Users were provided with clear options to return to the main page or to continue reviewing history.
Throughout all workflows, error handling and validation mechanisms were implemented to ensure system stability and enhance the user experience. The control flow diagram employs color-coded elements and logical connectors to clearly represent the various activities, decision points, and interactions with the database. This approach supports systematic operation of the GabayPalay application, promotes accurate data processing, and maintains consistent functionality for both yield prediction and record management.
User interface design and implementation
User interface design prioritized accessibility, simplicity, and effectiveness for rice farmers with diverse technological backgrounds and experience levels. Design principles emphasized intuitive navigation, clear visual hierarchy, and minimal cognitive load to reduce learning requirements and maximize adoption potential.
The interface design accommodated findings from Angchay et al. (2024) regarding technology adoption challenges among farmers in Davao del Sur, including digital literacy gaps and device compatibility issues. Design solutions addressed these constraints through simplified interaction patterns, clear visual feedback, and robust error prevention mechanisms.
Input interface design utilized familiar form-based layouts with clear labeling, appropriate input types, and contextual guidance. Numeric inputs incorporated validation mechanisms to prevent common entry errors while providing immediate feedback regarding acceptable value ranges. Progressive disclosure techniques minimize interface complexity while maintaining access to comprehensive functionality.
The results presentation emphasized clear visualization of yield predictions with contextual information to support farmer decision-making. Output displays included numerical predictions, graphical representations, and textual explanations to accommodate different user preferences and comprehension levels.
Navigation design employed consistent patterns throughout the application, with clear pathways between primary functions and obvious methods for returning to previous states. The interface maintained visual consistency with established Android design guidelines while incorporating agricultural imagery and terminology familiar to the target user population.
 
UI design mockups
The user interface design mockups, presented in Appendix 5, provided comprehensive visualization of the GabayPalay application's key screens and interaction elements. These mockups established the visual foundation for development while demonstrating adherence to usability principles and user requirements.
The main dashboard mockup featured prominent access to core prediction functionality, historical data review, and application settings. Visual design emphasized clarity and simplicity, with clear calls-to-action and intuitive icon usage to guide user navigation.
Input form mockups demonstrated the systematic organization of agronomic data entry fields, including land area specification, seed usage rates, fertilizer applications, and pesticide usage patterns. Form design incorporated progressive disclosure techniques to reduce cognitive load while maintaining comprehensive data collection capabilities.
Prediction results mockups illustrated the presentation of yield estimates with supporting information including confidence levels, historical comparisons, and actionable recommendations. Visual design balanced detailed information provision with comprehensible presentation suitable for users with varying technological experience.
Error handling and feedback mockups demonstrated the application's approach to input validation, error prevention, and user guidance. Design solutions provided clear error messages, correction guidance, and recovery pathways to maintain positive user experience during challenging interactions.
The mockups incorporated responsive design principles to ensure consistent functionality across different Android device configurations and screen sizes commonly used by farmers in the target region. Visual consistency maintained application identity while adapting to device-specific constraints and capabilities.
System integration and compatibility
System integration procedures ensured seamless operation of application components while maintaining compatibility with diverse Android device configurations used by the target farmer population. Integration testing validated data flow integrity, model performance consistency, and user interface responsiveness across different operational scenarios.
Compatibility requirements addressed the minimum device specifications identified during requirements planning, including Android 8.0 (Oreo) or higher, 2GB RAM, and 16GB internal storage. Performance optimization ensured responsive operation within these constraints while maintaining prediction accuracy and user experience quality.
Offline functionality implementation required careful integration of the converted Random Forest model with local data storage and processing capabilities. Testing procedures validated prediction consistency between the original Python implementation and the deployed Kotlin version to ensure model reliability in the mobile environment.
Security considerations addressed data protection requirements for farmer information and prediction results stored locally on devices. Implementation included data encryption for stored information, secure data validation processes, and privacy protection mechanisms aligned with ethical research standards established in Phase 1.
Phase 4: Construction and Implementation
The construction and implementation phase represented the culmination of the RAD methodology, transforming design specifications and architectural plans into a functional mobile application. This phase focused on systematic development, rigorous testing, and seamless integration of all system components to deliver the GabayPalay mobile application for rice yield prediction.
Development environment and technology stack
The development environment was established using Android Studio as the primary integrated development environment (IDE), providing comprehensive tools for Android application development, debugging, and testing. The technology stack was selected to ensure optimal performance, maintainability, and compatibility with the target device specifications identified during requirements planning.
The core programming language utilized Kotlin, chosen for its modern syntax, null safety features, and seamless interoperability with existing Android libraries. Kotlin's concise syntax and enhanced safety features reduced development time while improving code reliability and maintainability throughout the implementation process.
Development was carried out using Android Studio and the native SDK, targeting API level 26 (Android 8.0 Oreo) and above. This configuration was selected to fulfill the minimum device requirements specified in the non-functional requirements section, ensuring compatibility and reliable performance on devices accessible to the intended users. The application was optimized and tested for operation on devices with at least 2GB RAM and 16GB internal storage and included support for offline usage to accommodate rural connectivity constraints.
Database implementation utilized SQLite for local data storage, providing reliable offline functionality without requiring internet connectivity. SQLite's lightweight architecture and robust data management capabilities aligned with the application's requirement for independent operation in areas with limited network infrastructure.
User interface development was implemented using XML layouts for the front-end, ensuring consistency with Android UI guidelines and accessibility for users with varying technological backgrounds. The UI framework emphasized simplicity and clarity, addressing the usability requirements identified during user research activities.
Version control systems employed Git with GitHub repositories to maintain code integrity, track development progress, and facilitate collaborative development processes. Automated backup procedures ensured code security and enabled rollback capabilities during development iterations.
Model integration process
The model integration process began with training and optimizing a Random Forest regression model in Python using the scikit-learn library. After selecting the best-performing model through grid search and cross-validation, the model was serialized and evaluated to ensure reliable prediction accuracy and consistent performance across all data samples. Feature importance values were also extracted to support interpretability in subsequent application development.
To enable offline predictions on Android devices, the m2cgen library was used to automatically convert the trained model into Kotlin code. The generated code and feature importance utilities were integrated into the mobile application, with thorough validation to confirm consistency between Python and Kotlin predictions. Additional performance testing and error handling were conducted to guarantee stability and reliability even on resource-constrained devices.
Database implementation
Database implementation established a comprehensive local storage system using SQLite to support offline functionality and historical data management. The database schema was designed to accommodate agronomic input variables, prediction results, and application metadata while maintaining data integrity and query efficiency.
The main data tables included records of input variables for each prediction session, farm characteristics such as land area and location details, and prediction history storing yield estimates with associated confidence measures and timestamps. Data validation procedures ensured input consistency and completeness before database storage, helping maintain data reliability throughout the application lifecycle.
Indexing strategies optimized query performance for common operations including historical data retrieval, trend analysis, and report generation. Database optimization addresses storage efficiency concerns while maintaining rapid access to frequently requested information.
Data security implementation included local encryption for sensitive information and prediction results. Security measures addressed privacy protection requirements established during the ethical considerations phase while ensuring data accessibility for legitimate application functions. Backup and recovery procedures provided data protection against device failures, application errors, and user mistakes. Automated backup mechanisms preserved critical information while enabling data restoration and migration capabilities for device upgrades or replacements.


Unit testing and integration testing
Comprehensive testing procedures ensured the reliability, functionality, and performance of the application across different scenarios and device types. Both automated and manual testing approaches were used to validate input validation, prediction algorithms, database operations, and user interface elements. Model outputs in Kotlin were thoroughly checked for consistency against the original Python implementation. Database and UI testing covered data integrity, query efficiency, and responsiveness on various Android devices. Integration and performance tests confirmed smooth operation, resource usage, and stability under typical and intensive conditions.
Error logging and monitoring systems captured application performance data, user interaction patterns, and technical issues throughout the testing phases. This information guided iterative improvements and optimization efforts during development. Quality assurance procedures ensured that all identified issues were systematically addressed prior to deployment.
Alpha testing was conducted internally to verify system functionality, resolve operational errors, and assess consistency of model outputs with Python environment results. This phase identified and addressed technical issues before user evaluation activities.
Beta testing involved selected farmers from the target population in Hagonoy, Davao del Sur, providing real-world validation of application usability and functionality. Beta testing protocols included structured feedback collection using the System Usability Scale (SUS) and Technology Acceptance Model (TAM) instruments to evaluate user experience and acceptance levels.
Phase 5: Cutover and Validation
The cutover and validation phase represented the final stage of the RAD methodology, focusing on comprehensive testing, user acceptance evaluation, and systematic validation of the GabayPalay mobile application. This phase ensured that the developed application met all functional requirements, usability standards, and user expectations before deployment to the target farmer population in Hagonoy, Davao del Sur.
Testing framework overview
A comprehensive testing framework was established to ensure the GabayPalay application's functionality, performance, and usability across multiple evaluation dimensions. This framework integrated technical validation procedures with user-centered evaluation methods, providing a systematic approach to assessing the application's readiness for deployment.
The framework covered several validation layers, including functional testing for feature completeness and accuracy, performance testing for system responsiveness and resource usage, compatibility testing across target device configurations, and usability testing to evaluate the user experience and interface effectiveness.
Technical validation included regression testing to maintain consistency with the original Python implementation, stress testing under intensive usage scenarios, and security testing to ensure data protection and privacy. User validation incorporated structured feedback collection through standardized instruments, observational studies of user interactions, and evaluation of learning curves and adoption barriers. Both quantitative metrics and qualitative assessments were considered.
Throughout the evaluation process, quality assurance protocols ensured consistency in testing methodologies and systematic documentation of results for analysis and improvement planning. Error logging and monitoring systems captured application performance data, user interaction patterns, and technical issues, guiding iterative refinements and optimization efforts. The framework supported ongoing refinement based on testing outcomes while maintaining rigorous validation standards.
User acceptance testing framework
The user acceptance testing framework established a structured approach for evaluating the GabayPalay application's usability, functionality, and user satisfaction among the target farmer population. This process bridged the transition from technical validation to real-world assessment with actual end users.
Testing began with controlled sessions where individual farmers interacted with the application under guided conditions. These sessions enabled observation of user behaviors, identification of interaction difficulties, and assessment of learning needs for successful adoption.
Task-based scenarios were designed to reflect typical farming decision-making situations, guiding users through complete workflow cycles from data input to prediction interpretation and decision-making support. The framework addressed diverse user backgrounds and technological experience, accommodating farmers with varying digital literacy while maintaining consistent evaluation standards.
Feedback was collected using both quantitative instruments and qualitative interviews to capture comprehensive user perspectives on utility, usability, and adoption potential. The framework enabled systematic analysis of user acceptance factors and identified opportunities for improvement.
System usability scale assessment
The System Usability Scale (SUS), based on Brooke (1996), was used to quantitatively measure the usability of the GabayPalay application. The assessment was conducted using the ten-item questionnaire (see Appendix 6), rated on a 5-point Likert scale, following standard scoring procedures to produce final scores from 0 to 100. Participants included rice farmers and individuals with relevant technological experience.
SUS scores were interpreted using established benchmarks (Sauro, 2016): scores above 70 indicated acceptable usability, above 80 signified good usability, and above 90 reflected excellent usability. These thresholds provided clear standards for evaluating the application's user experience. The analysis included calculation of mean scores, standard deviations, and confidence intervals to characterize overall performance. Additionally, item-level assessment was conducted to identify specific areas for improvement and guide targeted refinements in the application's design.
Technology acceptance model evaluation
The Technology Acceptance Model (TAM), from Davis (1989), assessed user acceptance in terms of perceived usefulness, ease of use, and behavioral intention. The evaluation used a structured questionnaire (see Appendix 7) to capture user perceptions of the application's practical benefits, interface clarity, and willingness to adopt.
Descriptive statistics summarized TAM responses, with correlation analysis exploring links between usefulness, ease of use, and adoption intention. Qualitative feedback provided additional context for user acceptance and highlighted features impacting evaluations. Comparative analysis identified patterns across user backgrounds and informed recommendations for support and training.
Combined SUS and TAM results offered a comprehensive picture of the GabayPalay application's usability and acceptance among rice farmers, guiding final refinements and deployment strategies to enhance adoption and long-term success.
