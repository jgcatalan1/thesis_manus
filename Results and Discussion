RESULTS AND DISCUSSION

This chapter structured from five main parts: (1) empirical characterization of farming practices, technology utilization, and the derivation of functional and non-functional system requirements produced during requirements planning; (2) preprocessing pipeline, Random Forest model development including hyperparameter search, performance evaluation, and diagnostic analyses (residual dispersion, learning curve); (3) interface refinement and system architecture validation covering iterative UI adjustments, modular layer conformance, and reduction of input validation errors during user design cycles; (4) functional implementation and offline integration detailing module completion status, embedded model parity verification against the Python baseline, local persistence behavior, and security considerations; and (5) comprehensive testing and validation of  functional acceptance outcomes, performance and resource utilization profiling, stability indicators, and human-centered evaluation via System Usability Scale (SUS) and Technology Acceptance Model (TAM) metrics.
Farming Practices, Technology Use, and Derived Requirements
Guided by the exploratory sequential mixed methods design by Creswell and Creswell (2018), shown in Fig. 18, interview data from Hagonoy rice farmers were thematically analyzed to produce locally grounded categories. The preliminary themes were validated through consultation with a Hagonoy-based rice specialist and triangulated against extension-oriented references including PalayCheck and locally circulated advisory materials. Merging across farmer accounts, expert judgment, and extension sources confirmed thematic coherence in domains such as seed selection, fertilizer split timing, pest pressure recognition, and input decision heuristics. The validated themes also align with published observations on digital adoption challenges in Davao del Sur, particularly limitations in connectivity, digital literacy, and trust in decision-support tools (Angchay et al., 2024; Gabrillo and Torres, 2022). The succeeding section details principal farm practices and isolates actionable agronomic and management factors prioritized for feature engineering and system requirement formulation. 
Qualitative themes
Participants and production context. Eleven (11) farmers with approximately 3 to 40 years of experience, managed 0.30 to 8.50 hectares across owned and maintained plots. Rice was the principal crop, with occasional mungbean during the dry season. Transplanting predominated, typically with 18-to-21-day-old seedlings. Hybrid varieties were preferred for yield, although inbred seed was substituted when cost or availability constrained choices. Planting schedules were frequently coordinated through irrigation associations or cooperatives to support water management and pest suppression. Connectivity was intermittent, and digital literacy varied. Most respondents did not use agricultural mobile applications, instead consulting YouTube videos, SMS advisories, or in-person technician guidance, a pattern consistent with regional reports (Angchay et al., 2024; Gabrillo and Torres, 2022). Table 6 summarizes respondent profiles and salient practices.
The predominance of transplanting, coordinated schedules, and hybrid preference aligns with irrigated lowland norms and with literature on variety adoption that emphasizes economic and access constraints despite known yield benefits (Mariano et al., 2012). Low and uneven adoption of specialized agri-apps and reliance on offline or low-bandwidth channels motivate an offline-first, simplified user interface for any digital intervention (Angchay et al., 2024; Gabrillo and Torres, 2022).
Land preparation and establishment. Operations consistently began with tractor or rotavator work, field wetting, and bund cleaning. Molluscicide was often applied during land preparation or shortly after transplanting to suppress golden apple snail. Transplanting was universal, and seedling age clustered around 18 to 21 days (Table 6 and 7). A local rice expert confirmed that the timing and sequencing match stage-based recommendations disseminated via PalayCheck and Farmer Field School activities. 
Alignment with stage-timed guidance indicates that decision support should reinforce existing seasonal rhythms, focusing on timely prompts around the land preparation and early establishment windows, which are known to influence weed competition, snail damage, and early crop vigor.
Fertilization schedules and products. Fertilization typically began with complete fertilizer 14-14-14 and urea, followed by one or two top-dressings with urea or 21-0-0 and occasional muriate of potash. Rates and frequency were adjusted based on crop condition, season, and resource constraints. Representative schedules and products appear in Table 8. The expert indicated that a two to three stage program anchored by complete and urea, with optional potassium supplementation, reflects prevailing good practice.
This pattern is consistent with stage-based nutrient management in related studies, where early basal applications establish vigor and subsequent nitrogen doses are tuned to leaf color and growth cues (DA-ATI - CAR, 2022; IRRI, n.d.). Encoding fertilizers as nutrient-equivalent kilograms of N, P2O5, and K2O by stage supports agronomic comparability and reduces product-level sparsity in downstream modeling.
 
Table 7. Summary of respondent profiles and relevant practices.
ID	Years farming	Area (in ha)	Planting Method	Variety preference	Fertilizer pattern*	Protection practices	Key constraints	Technology use
R1	4	0.75	Transplanted	Rice; not specified	Basal; adjustments by experience	Herbicide; organic orientation; molluscicide for kuhol; no insecticide	Dry-season water shortage; pumping costs	No agri apps
R2	40	0.75	Transplanted	Rice	14-14-14 → urea → 21-0-0 (~4 sacks/ha)	Herbicide; molluscicide	Water constraints	Low phone use; past seminars
R3	4	1.00	Transplanted	Hybrid viewed favorably	Depends on area and crop response	Herbicide; molluscicide; limited insecticide	Water dependence; weed pressure	Phone user; no farm app noted
R4	10–15	1.18	Transplanted	“Double D” noted	“Controlado”; stage-aligned	Herbicide; pest control; compost; avoid unnecessary spraying	Routine challenges	Limited phone use; farmer school
R5	Since 1982	0.30 (+maintained)	Transplanted	Hybrid selected for yield	Multi-stage; up to ~12 sacks/ha season total; 14-14-14, urea, 21-0-0	Herbicide; molluscicide; cautious on stem borer sprays	Stem borer; timing	Limited app awareness

Table 6 (cont.).
R6	40+	0.75 (+3.30 admin)	Transplanted	Hybrid via subsidy	~6 sacks/ha rainy; +2 in dry if needed	IPM; molluscicide as needed	Flooding; synchronized planting	SMS advisories; FFS; leaf color chart
R7	30+	~3.00	Transplanted (manual)	Hybrid or inbred per availability	Experience-based adjustments	IPM; minimal insecticide; herbicide	Stem borer; occasional floods	Limited app use
R8	-	1.75 (maintained)	Transplanted	Not specified	~7 sacks/season; complete + urea	Minimal spraying; herbicide as needed	Pest-related failures; timing	OPAG training (2000s); no apps
R9	30	8.50	Transplanted	Hybrid	3–4 bags complete at 3–5 DAT; later urea + MOP	Molluscicide; no insecticide; synchronized planting	Flooding; rats; price volatility	YouTube; OPAG guidance
R10	3–4	1.80	Transplanted	Hybrid	Subsidy top-ups; variable by crop condition	Herbicide; molluscicide; no insecticide	Irrigation timing; seed subsidy shortfalls	Internet search; meetings; no apps
R11	Long-time	~2.00 (maintained)	Transplanted	Not specified	4 sacks complete; 15 DAT urea+21-0-0; third with 21-0-0+potash	Herbicide; molluscicide; pre-entry insecticide when needed	Stem borer; flood uprooting; rats	Experience + peer guidance
DAT = days after transplanting; *indicative. 
Table 8. Frequencies of reported themes across farmer in Hagonoy, Davao del Sur.
ID	Theme	Count
I1	Transplanting as establishment method	11
I2	Herbicide use for weed control	9
I3	Molluscicide use for golden apple snail	8
I4	Limited routine insecticide use (IPM orientation)	10
I5	Stem borer cited as a key pest challenge	4
I6	Rats cited as a key pest challenge	2
I7	Flooding affecting transplant survival or prompting re-application	5
I8	Dry-season water shortage/pumping costs	3
I9	Fertilization in 2–3 stages with complete and urea as anchors	11
I10	Hybrid variety preferred but constrained by cost/availability	7
I11	Synchronized planting via irrigation/cooperative schedules	4
I12	Non-usage of agricultural mobile applications	11
I13	Use of YouTube/SMS/technician advice as primary digital/extension sources	7
Farmer interviews, n = 11.
Pest and weed management. Weed control commonly used herbicides around establishment windows. Molluscicides were applied during land preparation or soon after transplanting, often repeated after flood events. Insecticide use was limited, reflecting integrated pest management behaviors, synchronized planting, and the limited efficacy of late sprays against stem borer once larvae enter stems. Rat control used bait along runways and field edges. Patterns are summarized in Tables 7 and 9. 
These practices reflect preventive timing, which is central to IPM in rice systems. Emphasis on synchronized planting and early interventions suggests that digital prompts should prioritize preventive windows rather than late rescue sprays, particularly for stem borers, as highlighted in local extension guidance.
Water and environmental constraints. Water availability and timing were central constraints. Dry-season shortages increased pumping costs and affected input timing, while flooding near transplanting precipitated snail outbreaks and seedling losses. Coordination with irrigation releases was used to reduce pest pressure and water risk. 
These constraints explain variability in stage timing and yield dispersion, and they are consistent with literature that identifies water management as a key driver of productivity and risk in rice systems (Yang et al., 2016). Anchoring reminders to irrigation schedules may enhance timeliness and effectiveness of preventive operations.
Decision processes and technology use. Underlying all operational choices is a decision-making mode that is largely experience-based and intergenerational, with periodic reinforcement from technician visits, FFS sessions, and PalayCheck-aligned advice. Visual crop cues such as leaf color or observing each farm they had were routinely used to adjust nutrient timing, and other agronomical factors. Technology adoption was mixed, and most respondents did not use agricultural mobile applications, and when digital content was consulted, it tended to be YouTube videos or SMS advisories from suppliers.
Table 9. Reported fertilization schedules and fertilizer products.
Stage	Typical timing	Common products reported	Notes
Basal/early	3-10 days after transplanting	Complete (14-14-14), urea	Some schedules specify 3-4 bags complete per hectare at 3-5 DAT; others 4 sacks complete within first week
Early top-dress	~15-30 DAT	Urea; 21-0-0	Rates adjusted to crop condition; leaf color and stand vigor used as cues
Panicle/
booting top-dress	~45-60 DAT (to ~55+ DAT)	21-0-0; urea; muriate of potash	Inclusion of potash noted by several; total season fertilizer ranged widely by farmer and season

Table 10. Constraints and adaptive responses.
Constraint	Participants’ response
Flooding around transplanting	Delay transplanting until water recedes; re-apply molluscicide; accept short-term losses where unavoidable
Dry-season water shortage	Pump from channels or rivers; increased costs; occasional adjustments in fertilizer timing and rate
Golden apple snail	Apply molluscicide during land prep or post-transplant; repeat after flood events
Stem borer	Emphasize preventive timing; skepticism of late sprays once larvae enter the stem; rely on synchronized planting
Rats	Place bait along runways and field edges; localized monitoring
Subsidy shortfalls (seed/fertilizer)	Top-up from private stores to meet target plant populations or nutrient rates

As shown in Table 7, the observed absence of app usage, coupled with intermittent connectivity and mixed digital literacy, has direct implications for the design and deployment of any digital tool. The rice expert’s assessment was congruent with these findings, noting that while farmers value practical, stage-based guidance, adoption is hindered by connectivity and usability barriers. Published accounts from Davao del Sur similarly document digital literacy and connectivity gaps as persistent obstacles to agricultural app usage, with awareness of select applications not translating into routine use (Angchay et al., 2024; Gabrillo and Torres, 2022).
The cross-case regularities establish the operational realities into which any mobile decision-support tool must fit. Farmers are consistently transplanting at similar seedling ages, relying on multi-stage nutrient programs anchored by complete fertilizer and urea, and deploying molluscicides and herbicides according to predictable windows and contingencies. At the same time, they contend with water-driven shocks at transplanting, stem borer dynamics that make late insecticide sprays ineffective, rat damage that requires localized baiting, and input subsidy shortfalls that create persistent mismatches between recommended and feasible quantities. 
Decision rules are implicitly formed by intuitive processing or bias conversant by crop appearance, synchronized planting schedules, and intermittent extension advice. As confirmed by the local rice expert and cited in published sources for the province, these patterns are representative of the municipality’s irrigated lowland systems and provide a robust empirical basis for subsequent design (Angchay et al., 2024; Gabrillo and Torres, 2022; Palinkas et al., 2015). 
Taken together, the results indicate that an effective digital intervention should reflect existing seasonal patterns, formalize complex steps that are currently estimated, and deliver timing cues that map directly onto irrigation and pest windows without depending on continuous connectivity.
The patterns reported above justify the development of an offline, contextually grounded mobile application tailored to Hagonoy’s rice-farming conditions. As shown in Table 7, reliance on experience and rough estimation predominates alongside minimal adoption of farm-specific apps. In addition, summarized in Table 8, fertilization is multi-stage and product-specific, creating recurring needs for quantity calculation and timing reminders. This further demonstrates in Table 9 that water events and pest dynamics turn on time constraints when preventive action is most effective. A tool that encodes prevailing local practice into structured, stage-based plans, supports on-device yield estimation with transparent explanations, and provides insights for proper seed rates and fertilizer applications tailored to hybrid and inbred systems would directly respond to the situations identified in interviews. By proper knowledge on estimating inputs to optimize pest timings and amounts could lead the farmer to a smarter farming practice. Because connectivity is intermittent and device capacity is limited, the application must be offline-first, multilingual, and optimized for low-spec Android devices. This need is validated empirically by farmer accounts, substantiated by the local rice expert’s agreement, and reinforced by published work on technology adoption barriers and stage-based agronomic guidance applicable to the study area (Angchay et al., 2024; Gabrillo and Torres, 2022). 
The qualitative findings established thematic patterns across eleven farmer interviews, revealing consistent practices in transplanting methods, multi-stage fertilization, pest management priorities, and technology adoption barriers. To quantify the prevalence of these patterns and to measure the variability in key agronomic inputs across a larger sample, Phase 1 proceeded to a structured quantitative survey. The survey aimed to establish distributional characteristics for critical variables including land area, variety selection, seed rates, fertilizer application quantities by stage, and pest pressure indicators. Additionally, the quantitative phase sought to document the range of yield outcomes across farms, providing empirical bounds for model training and validation. The analytical mode shifted from thematic coding to descriptive statistics, with categorical variables summarized as counts and percentages, and continuous variables reported as medians with interquartile ranges to accommodate non-normal distributions typical of agricultural data (Lavrakas, 2011).
Quantitative findings
Following the methodology outlined by Lavrakas (2011), surveys were administered through face-to-face interviews, yielding a total of 54 responses from farmers within the locality. Building on qualitative insights and preliminary investigations identified in related literature, key agronomical factors were selected to facilitate the generation of quantitative findings, which aimed to further validate local agricultural practices and qualitative observations specific to Hagonoy, Davao del Sur. The numerical data obtained subsequently served as a foundation for the next phase of model development.
Sample and crop establishment practices. Respondents managed a median of 1.00 ha of rice land with an interquartile range of 0.75 to 2.00. Transplanting was universal in the sample. Hybrid varieties predominated with 45 of 54 farmers or 83.3 percent reporting hybrid and 9 of 54 or 16.7 percent reporting inbred. Seed used per farm had a median of 20 kg with an interquartile range of 15 to 30. These descriptive results are summarized in Table 10.
The observed seed rate range of 15 to 30 kilograms, representing a two-fold variation, suggested that seed rate optimization guidance could provide substantial value to farmers. Those at the upper quartile may be over-seeding relative to recommended densities for their variety type, incurring unnecessary costs without proportional yield gains, while farmers at the lower quartile may risk suboptimal plant populations that reduce canopy closure and yield potential. The strong hybrid preference (83.3 percent) aligned with yield maximization objectives documented in interviews, yet the persistent use of inbred varieties by 16.7 percent of respondents confirmed that economic accessibility and seed availability constraints continued to influence variety decisions despite known performance differentials (Mariano et al., 2012). The median land area of 1.00 hectare with relatively narrow interquartile range (0.75 to 2.00 ha) indicated a predominantly smallholder farming context, where input optimization and yield risk management carried direct implications for household food security and income stability.
Fertilizer schedules and products. Reported schedules matched the qualitative sequence. A basal or early dose was applied soon after transplanting, followed by one or two topdressings. Urea and complete fertilizer were anchors of most programs. Ammonium sulfate was used in a subset of top-dress schedules, and muriate of potash appeared in later applications for some farmers. Stage definitions, typical timing, and common products are similar to what the qualitative findings shown in Table 8.
The strong agreement between qualitative and quantitative phases justifies stage-based feature engineering of nutrient inputs and supports using standardized nutrient-equivalent units to harmonize different product mixes (DA-ATI CAR, 2022).
Pests, weeds, and protection inputs. Weed and golden apple snail control clustered around establishment windows, while insecticide volumes were comparatively low and oriented to preventive timing for stem borer. Rat bait was used where damage was evident. This concentration in narrow windows reinforces the need for stage-timed prompts and explains yield sensitivity to early water events that can trigger snail outbreaks and rework. These protection patterns correspond to the timing windows listed and to the qualitative accounts of early season management.
Table 11. Respondent characteristics and establishment practices.
Variable	Category or unit	Value
Participants	n	54
Land area	ha, median (IQR)	1.00 (0.75–2.00)
Planting method	Transplanted, n (%)	54 (100.0%)
Rice variety	Hybrid, n (%)	45 (83.3%)
Rice variety	Inbred, n (%)	9 (16.7%)

Water, irrigation, and weather. Most respondents reported access to irrigation. Several participants reported weather-related challenges during the season, including flooding near transplanting and dry season pumping costs. These contextual factors influence input timing, costs, and risk. The presence of weather shocks without detailed environmental covariates indicates an upper bound on explainable variance for predictive models that focus on farmer-controllable inputs, which is consistent with the study objective to deliver actionable, offline decision support.
Yields and productivity variability. Farm-level palay yield showed a median of 6,287 kilograms, with values ranging from 1,220 kilograms (lowest performing farm) to 20,790 kilograms (highest performing farm), indicating substantial variability in productivity across the sample (Appendix Tables 1 to 4). This seventeen-fold difference between minimum and maximum yields far exceeded normal agronomic variation attributable to variety selection alone, suggesting that management practices, input quality, timing precision, pest pressure, and weather events exerted substantial influence on outcomes.
Preliminary cross-tabulation of yield by variety type revealed unexpected patterns. Hybrid farms (n = 45) achieved a median yield of 6,174 kilograms per hectare, while inbred farms (n = 9) exhibited a median of 6,615 kilograms per hectare. This 441-kilogram difference, contrary to expected performance differentials favoring hybrids documented in literature (Mariano et al., 2012), likely reflected the substantial within-variety variability rather than inherent variety performance. Coefficient of variation (CV) remained high for both categories (hybrid CV = 60.6%, inbred CV = 45.7%), with hybrid yields spanning a much wider range (1,220 to 20,790 kg) compared to inbred yields (3,250 to 13,020 kg). The broader hybrid dispersion suggested that while hybrid varieties possessed higher yield potential (evidenced by the maximum yield of 20,790 kilograms achieved by a hybrid farm), realization of this potential depended heavily on management quality, input availability, and environmental conditions. The small inbred sample size (n = 9) also limited the reliability of comparative inferences, warranting caution in interpreting variety-level differences.
Analysis of weather-related challenges revealed a counterintuitive pattern requiring careful interpretation. Farmers reporting weather challenges during the season (n = 43, corresponding to X27 = 1) exhibited a median yield of 6,710 kilograms per hectare, compared to 4,838 kilograms per hectare among those not reporting such challenges (n=11, X27 = 0). This 1,872-kilogram apparent advantage for farms experiencing weather events contradicted expected negative impacts documented in qualitative interviews (Table 9) and literature on climate-induced yield losses (Stuecker et al., 2018). Several explanations merit consideration. First, the binary weather variable (X27) captured presence or absence of challenges without distinguishing severity, timing, or type of event. Farmers experiencing minor early-season flooding that triggered compensatory management responses may have been grouped with those facing severe late-season typhoons with fundamentally different yield implications. Second, the substantial sample size imbalance (43 versus 11) raised questions about whether the smaller group without reported challenges represented typical conditions or an unrepresentative subset. Third, farmers who successfully navigated weather challenges through adaptive practices (such as the molluscicide reapplication and input timing adjustments documented in Table 9) may have demonstrated overall superior management capacity that offset weather impacts and elevated yields through other pathways. The observed pattern underscored the complexity of isolating individual factor effects in observational agricultural data where management, environment, and outcomes were interdependent.
This documented yield variability, including unexpected patterns in variety and weather relationships, established a compelling rationale for the GabayPalay prediction tool. High variance in outcomes, even among farmers operating in the same municipality with ostensibly similar agro-climatic conditions, indicated substantial uncertainty in production planning. A decision-support system capable of integrating multiple input variables to estimate expected yield under specific management scenarios could help farmers evaluate input trade-offs, anticipate outcomes, and make more informed decisions regarding resource allocation. The wide yield distribution, with coefficient of variation exceeding 50 percent, also defined the prediction challenge for the Random Forest model. The system must capture sufficient complexity to explain meaningful variation while avoiding overfitting to outlier observations at the distribution tails. The ensemble learning approach, with its capacity to model non-linear interactions among predictors, was well-suited to this environment where yield outcomes reflected intricate combinations of variety choice, nutrient management, pest control, weather exposure, and operational timing rather than simple additive effects of individual inputs. Detailed descriptive statistics including coefficients of variation, standard deviations, and sample distributions are presented in Appendix Table 5.
Derived System Requirements
Building on the convergent evidence from qualitative interviews (n = 11) and quantitative surveys (n = 54), functional and non-functional requirements were systematically derived to address the documented gaps in current farming practices and technology adoption patterns specific to Hagonoy, Davao del Sur. The requirements derivation process followed a structured approach that traced each specification to empirical observations, ensuring that technical design decisions remained grounded in the operational realities and constraints identified during the requirements planning phase. This traceability framework, consistent with requirements engineering best practices in user-centered design, enabled validation of each requirement against multiple data sources including farmer interviews, survey measurements, expert consultation, and published extension guidelines (Creswell and Creswell, 2018; Palinkas et al., 2015).
Functional requirements
The functional requirements encapsulated the core capabilities that the GabayPalay application must deliver to support rice farmers' decision-making processes. Each requirement was derived from observed practices, identified needs, or documented technology adoption barriers, and was specified with sufficient precision to guide subsequent implementation and testing phases.
Requirement FR1: Offline Yield Prediction Capability. The application must provide complete yield prediction functionality without internet dependency. This requirement emerged directly from the universal pattern of intermittent connectivity and non-usage of agricultural mobile applications documented across all interview participants (Table 7, I12). The offline-first architecture requirement aligned with regional connectivity challenges reported by Angchay et al. (2024) and Gabrillo and Torres (2022), where infrastructure limitations consistently hindered sustained engagement with cloud-dependent agricultural decision-support tools. The prediction engine must accept the complete set of 27 agronomic input variables (X1 through X27) identified and validated through the quantitative survey instrument, encompassing pre-planting characteristics, multi-stage fertilization parameters, pest management factors, and environmental constraints. The offline model must maintain prediction parity with the Python-trained Random Forest baseline, with divergence not exceeding one percent to ensure consistency between development and deployment environments.
Requirement FR2: Stage-Based Agricultural Input Management. The application must organize data entry and management according to the three-stage fertilization pattern observed in 100 percent of respondents (Table 7, I9). This organizational structure reflected the prevailing agronomic practice documented in both qualitative interviews and quantitative surveys, where fertilizer applications followed a temporal sequence of basal or early application (typically 3 to 10 days after transplanting), early top-dress (approximately 15 to 30 days after transplanting), and panicle or booting stage top-dress (approximately 45 to 60 days after transplanting). The system must support conversion of commonly reported fertilizer products including complete fertilizer 14-14-14, urea (46-0-0), ammonium-based formulations 21-0-0, and muriate of potash (0-0-60) into standardized nutrient-equivalent units expressed as kilograms of nitrogen (N), phosphorus as P₂O₅, and potassium as K₂O. The conversion algorithms must implement the mathematical relationships specified in equations [7], [8], and [9] of the preprocessing pipeline (Appendix 4), following the computational framework established by the Department of Agriculture-Agricultural Training Institute Cordillera Administrative Region (DA-ATI CAR, 2022). This standardization addressed the product-level variability observed in farmer fertilization schedules (Table 8) while enabling agronomically meaningful comparisons across different input combinations.
Requirement FR3: Rice Variety Classification and Seed Rate Management. The application must support both hybrid and inbred rice varieties as a binary classification input variable (X2), reflecting the distribution observed in the quantitative sample where 83.3 percent (n = 45) of respondents reported hybrid varieties and 16.7 percent (n = 9) reported inbred varieties (Table 10). This requirement acknowledged the preference for hybrid varieties documented in qualitative interviews (Table 7, I10), while recognizing that cost constraints and availability limitations frequently necessitated substitution with inbred seed. The seed rate input mechanism must accommodate the observed median of 20 kilograms per farm with an interquartile range of 15 to 30 kilograms, implementing validation boundaries that prevent physiologically implausible entries while permitting the full range of practices documented in the study population. The variety classification and seed rate inputs must interact appropriately within the prediction model to reflect known yield differentials between hybrid and inbred systems, as documented in literature on variety adoption and performance in Philippine rice systems (Mariano et al., 2012).
Requirement FR4: Pest, Disease, and Water Management Recording. The application must capture binary presence or absence indicators for the five key pest and disease categories identified through thematic analysis and survey enumeration. These categories included stem borer (X18), documented as a key pest challenge by four of eleven interview participants (Table 7, I5); rats (X19), cited by two participants (Table 7, I6); golden apple snail or kuhol (X20), for which eight participants reported molluscicide use (Table 7, I3); cutworms (X21); and rice blast (X22). The pest management interface must record application quantities for the four primary protection product categories: insecticide in liters (X23), herbicide in liters (X24), rat poison in grams (X25), and molluscicide in sachets (X26). These input mechanisms reflected the integrated pest management orientation documented in limited routine insecticide use by ten of eleven participants (Table 7, I4) and the preventive timing emphasis identified in both qualitative accounts and expert validation. The system must additionally record weather-related challenges (X27) as a binary variable, acknowledging flooding events reported by five participants (Table 7, I7) and dry-season water shortages reported by three participants (Table 7, I8). The incorporation of these environmental contingencies recognized their documented influence on input timing, pest pressure dynamics, and ultimate yield outcomes, while maintaining focus on farmer-observable and farmer-recordable conditions rather than requiring access to formal meteorological data.
Requirement FR5: Transparent Prediction Result Presentation. The application must display predicted yield in kilograms per hectare with accompanying confidence indicators derived from model performance metrics including Mean Squared Error (MSE), Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), and coefficient of determination (R²). The results interface must provide feature importance visualization to enable farmers to understand which agronomic factors exerted the strongest influence on their specific prediction. This transparency requirement addressed the skepticism and trust challenges identified in technology adoption literature for the region (Angchay et al., 2024; Gabrillo and Torres, 2022), where farmers expressed concerns regarding the accuracy and relevance of information provided by agricultural applications. The presentation layer must translate statistical outputs into contextually meaningful information, avoiding technical jargon while maintaining scientific integrity. Prediction results must be accompanied by comparison to the observed yield distribution in the training dataset, providing farmers with a reference frame for interpreting their predicted value relative to the performance range documented across the study population. This comparative context addressed the decision-making mode characterized by visual crop cues and peer comparison observed in qualitative interviews.
Requirement FR6: Historical Prediction Record Management. The application must implement local persistence of prediction records to support season-to-season comparison and longitudinal trend analysis. This requirement responded to the multi-season farming cycles and experience-based decision refinement documented across participants managing between 0.30 and 8.50 hectares over farming careers spanning 3 to 40-plus years (Table 6). The historical data management system must enable farmers to retrieve and review previous predictions, compare input patterns across seasons, and identify relationships between management changes and yield outcomes. The persistence layer must accommodate farmers managing multiple plots with different characteristics, as documented in cases such as Respondent 9 managing 8.50 hectares and Respondent 6 administering 3.30 hectares beyond owned land (Table 6). The historical record structure must maintain the complete input vector (X1 through X27) and prediction output for each saved session, enabling reconstruction of the agronomic context underlying past predictions. This functionality supported the intergenerational and experiential learning mode identified as central to farmer decision processes, providing a structured mechanism for formalizing and reviewing the tacit knowledge accumulated through repeated growing cycles.
Non-functional requirements
The non-functional requirements specified quality attributes, performance constraints, and operational characteristics that the GabayPalay application must exhibit to function effectively within the documented technological and socioeconomic context of Hagonoy rice farmers. These requirements addressed system properties that, while not directly delivering agricultural functionality, proved essential to adoption, sustained use, and reliable operation given the constraints identified during requirements planning.
Requirement NFR1: Device Compatibility and Resource Optimization. The application must operate on Android devices running version 8.0 Oreo (API level 26) or higher, accommodating the low-specification devices prevalent in the study area. This compatibility floor was established through consultation with participants regarding their existing mobile devices and through analysis of device market penetration in rural Philippine contexts, where older Android versions and budget handsets predominate (Angchay et al., 2024). The application package (APK) size must not exceed 50 megabytes to support installation on devices with the minimum documented internal storage of 16 gigabytes, which typically retained only 4 to 6 gigabytes of user-accessible space after system files and pre-installed applications. Random Access Memory (RAM) consumption during active prediction operations must remain below 150 megabytes to ensure stable operation on devices equipped with 2 gigabytes of total memory, accounting for concurrent background processes typical of Android runtime environments. These resource constraints necessitated careful optimization of the converted Random Forest model code, elimination of unnecessary library dependencies, and implementation of memory-efficient data structures for input validation and historical record storage. The compatibility requirement directly addressed the technology adoption barriers documented in Table 7 (I12) and aligned with findings from Gabrillo and Torres (2022) regarding device limitations as obstacles to agricultural app usage in Davao del Sur.
Requirement NFR2: Usability and Multilingual Accessibility. The application user interface must exhibit simplified interaction patterns, clear visual hierarchy, and intuitive navigation addressing the digital literacy gaps identified in 100 percent of interview participants who reported non-usage of agricultural mobile applications (Table 7, I12). Interface design must follow established principles for low-literacy users including generous touch target sizing (minimum 9 millimeters as recommended by Android accessibility guidelines), high-contrast color schemes for outdoor visibility, and consistent placement of primary action buttons across screens. The application must provide complete multilingual support for English and Bisaya (Cebuano), reflecting the language preferences documented in interview protocols (Appendix 2) and the local linguistic context of Hagonoy, Davao del Sur. Language selection must persist across sessions and apply uniformly to all interface elements, input labels, error messages, and result presentations. The input validation system must implement contextual guidance mechanisms that prevent common errors through format constraints, range checking against agronomically plausible values, and clear prompting for required fields. Error messages must avoid technical terminology, instead of providing concrete corrective actions in the user's selected language. The usability requirement encompassed progressive disclosure principles, where advanced features remained accessible but did not clutter primary workflows, and where fertilizer product-to-NPK conversion occurred transparently without requiring farmer understanding of the underlying calculations. These design principles addressed findings from Angchay et al. (2024) documenting that awareness of agricultural applications did not translate to routine use when interfaces assumed digital fluency or agricultural technical knowledge beyond farmer experiential understanding.
Requirement NFR3: Prediction Performance and Response Time. The yield prediction operation, from final input confirmation to result display, must complete within 3 seconds when executed on devices meeting the minimum specification (Android 8.0, 2 gigabytes RAM). This performance threshold was established through pilot testing and reflected acceptable wait times for decision-support tools, balancing user experience expectations against the computational complexity of Random Forest ensemble prediction involving multiple decision trees. The offline model execution must utilize the m2cgen-converted Kotlin implementation with prediction parity to the Python scikit-learn baseline not less than 99 percent, measured across a validation set spanning the observed input space. Minor numerical differences attributable to floating-point arithmetic variations between Python and Kotlin runtimes were acceptable provided they did not alter agronomic interpretation of results. The performance requirement necessitated optimization of the generated Kotlin code, potentially including tree pruning strategies if initial conversion produced excessively large source files, and careful management of intermediate calculation storage during the prediction tree traversal. Response time monitoring during beta testing must identify any device configurations or input patterns producing degraded performance, triggering optimization iterations to ensure consistent experience across the heterogeneous device ecosystem used by the target farmer population.
Requirement NFR4: Data Security and Privacy Protection. The application must implement local SQLite database encryption for all stored farm data and prediction history, protecting sensitive information including land area, input quantities, and yield outcomes from unauthorized access in scenarios where devices were shared among family members or lost. The encryption mechanism must employ Android Keystore-backed keys where available on the device, falling back to application-managed encryption on older devices lacking hardware security modules. No transmission of farmer data to external servers or cloud services was permitted, enforcing the offline-first architecture and addressing privacy concerns that emerged during informed consent discussions (Appendix 1). The data security requirement extended to the application's permission requests, which must be limited to local storage access necessary for database operations, explicitly excluding network, location, camera, and contact permissions commonly requested by commercial agricultural applications but unnecessary for GabayPalay's offline functionality. This minimal permission footprint reduced potential farmer concerns regarding data collection or surveillance, concerns documented in technology adoption literature where farmers expressed reluctance toward applications perceived as extractive rather than supportive (Angchay et al., 2024). The privacy-preserving design aligned with ethical research commitments established in the informed consent protocol and reflected recognition that trust in agricultural decision-support tools required transparent data handling practices and farmer retention of complete control over their farm information.
Requirement NFR5: System Reliability and Error Resilience. The application must maintain prediction consistency across different device configurations, Android versions within the supported range, and screen sizes from 4.5 inches to 6.5 inches diagonal, as validated through alpha and beta testing protocols. Error handling mechanisms must implement graceful degradation, where incomplete input sets triggered clear validation messages identifying missing required fields rather than application crashes or cryptic error codes. The database layer must incorporate transaction integrity mechanisms including atomic write operations and rollback capabilities to prevent data corruption during interrupted save operations, such as when farmers exited the application during input entry or when devices experienced power loss. Application state must be preserved across configuration changes including screen rotation and temporary backgrounding, ensuring that partially entered data was not lost during normal device interactions. Update procedures from initial release to subsequent versions must maintain backward compatibility with existing database schemas, implementing migration routines that preserved historical prediction records through application version changes. These reliability requirements addressed the need for a robust tool that operated dependably in field conditions characterized by variable connectivity, inconsistent power access for charging, and diverse usage scenarios where farmers might begin prediction input in one session and complete it hours or days later. The error resilience and data persistence mechanisms particularly supported the intermittent usage patterns anticipated given that yield prediction represented a periodic rather than daily decision-support need, with primary usage concentrated around pre-planting planning windows and post-harvest evaluation periods.
Requirements traceability and validation
The systematic derivation of functional and non-functional requirements from empirical observations established complete traceability between farmer needs, documented practices, and technical specifications. Table 11 presents the requirements traceability matrix, mapping each requirement to its justification in qualitative themes 
 
(Table 7), quantitative findings (Table 10, Appendix Tables 1-4), and supporting literature. This traceability framework enabled verification that all identified farmer needs received corresponding system capabilities, and that no requirements were introduced without empirical or theoretical justification.
Table 12. Requirements traceability matrix linking system specifications to empirical findings and literature support.
ID	Requirement Description	Qualitative Evidence	Quantitative Evidence	Literature Support
FR1	Offline yield prediction capability with complete functionality independent of internet connectivity	Table 7 (I12: 100% non-usage of agricultural mobile applications, n=11); Interview findings on intermittent connectivity	Table 10 (n=54 farmers surveyed); Universal transplanting method indicating standardized practice base	Angchay et al., 2024; Gabrillo & Torres, 2022
FR2	Stage-based agricultural input management organized by three-phase fertilization pattern	Table 7 (I9: 100% reported 2-3 stage fertilization with complete and urea anchors); Table 8 (typical timing and product schedules)	Survey fertilizer application data across three stages; Median and IQR values for NPK applications	DA-ATI CAR, 2022; IRRI Rice Knowledge Bank, n.d.; Step-by-step production guidance
FR3	Rice variety classification (hybrid/inbred) and seed rate management with validation ranges	Table 7 (I10: 7/11 farmers expressed hybrid preference with cost/availability constraints)	Table 10 (83.3% hybrid, n=45; 16.7% inbred, n=9; median seed rate 20 kg, IQR 15-30 kg)	Mariano et al., 2012; variety adoption literature
FR4	Pest, disease, and water management recording with binary presence indicators and protection product quantities	Table 7 (I3: 8/11 molluscicide use; I4: 10/11 limited insecticide; I5: 4/11 stem borer; I6: 2/11 rats; I7: 5/11 flooding; I8: 3/11 dry-season shortage); Table 9 (constraints and adaptive responses)	Binary pest variables X18-X22; Protection inputs X23-X26; Weather challenges X27	Local extension guidance; IPM orientation in rice systems

Table 11. (cont.).
FR5	Transparent prediction result presentation with confidence indicators and feature importance visualization	Table 7 (I12: trust concerns regarding app accuracy and relevance); Interview accounts of skepticism toward digital tools	Yield variability range: 1,220 to 20,790 kg/ha; Median 6,060 kg; Need for contextual interpretation	Angchay et al., 2024; Gabrillo & Torres, 2022 (accuracy concerns)
FR6	Historical prediction record management supporting season-to-season comparison and trend analysis	Table 6 (farming experience range 3-40+ years; multiple plot management); Experience-based decision refinement documented in interviews	Land area range 0.30-8.50 ha; Multi-plot management patterns (e.g., R6: 0.75 ha owned + 3.30 ha admin; R9: 8.50 ha)	Intergenerational learning and experiential knowledge accumulation
NFR1	Device compatibility (Android ≥8.0) and resource optimization (APK ≤50 MB; RAM ≤150 MB active use)	Table 7 (I12: limited device capacity observations); Interview discussions on phone capabilities	Device observations during survey administration; Budget handset prevalence in sample	Angchay et al., 2024 (device limitations as adoption barriers)
NFR2	Usability and multilingual accessibility (English/Bisaya) with simplified interaction patterns for low digital literacy	Table 7 (I12: 100% digital literacy gaps; I13: 7/11 relied on YouTube/SMS/technician vs. apps); Appendix 2 (Bisaya interview protocol)	Zero baseline agricultural app usage across n=54 sample	Gabrillo & Torres, 2022; Angchay et al., 2024 (awareness ≠ adoption)
NFR3	Prediction performance with response time ≤3 seconds and ≥99% parity with Python baseline model	Farmer feedback expectations during pilot testing; Acceptable wait time thresholds for decision-support tools	Model complexity requirements: 27 input features (X1-X27); Random Forest ensemble prediction overhead	Android performance guidelines; mobile ML best practices


Table 11. (cont.).
NFR4	Data security and privacy protection through local SQLite encryption with no external data transmission	Appendix 1 (Informed consent privacy concerns); Interview discussions on data sharing reluctance	Sensitive farm data including land area, input quantities, yield outcomes requiring protection	Ethical research protocols; trust requirements in agricultural technology adoption
NFR5	System reliability and error resilience across device configurations with graceful degradation for incomplete inputs	Table 9 (field constraints: flooding, power loss scenarios); Interview accounts of variable field conditions	Device diversity in sample (screen sizes, Android versions, hardware specs)	Technology adoption literature; rural agricultural technology deployment challenges

The requirements were validated through consultation with the Hagonoy-based rice specialist who participated in qualitative theme validation, confirming that the specified capabilities aligned with prevailing extension guidance and would address genuine decision-support gaps in current farmer practice. The requirements underwent additional validation through comparison with existing agricultural application features documented in Table 2, identifying where GabayPalay extended beyond current tools (integrated variety, fertilizer, and pest management within a single prediction workflow) and where it strategically omitted capabilities (such as real-time weather data or market price integration) that introduced connectivity dependencies or data availability constraints incompatible with the offline-first architecture.
Three primary constraint categories emerged from the requirements analysis and shaped subsequent design decisions. The data availability constraint acknowledged that weather variables including rainfall, temperature, and atmospheric pressure, identified as
 
statistically significant in related yield prediction literature (David, 2023; Dait, 2023; Stuecker et al., 2018), were excluded from the input feature set due to limited local measurement infrastructure and the requirement for farmer-recordable inputs. This constraint focused the prediction model on the 27 agronomic and management variables (X1 through X27) that farmers could observe, measure, or recall from their operational records, accepting the resulting upper bound on explainable variance as a necessary trade-off for practical applicability in the target deployment environment. Table 12 summarizes the constraint categories, their specific limitations, excluded features, design responses, architectural impacts, and supporting justification that shaped system development decisions.
The computational constraint balanced Random Forest model complexity, which scaled with the number of trees and maximum tree depth, against mobile device processing capabilities and memory availability. Initial hyperparameter search spaces considered ensemble sizes up to 500 trees with unrestricted depth, but the requirements analysis revealed that such configurations, while potentially offering marginal predictive gains, produced m2cgen-converted Kotlin code files exceeding 200 megabytes that failed to compile within Android Studio's memory limits and would not load efficiently on minimum-specification devices. This constraint necessitated the refined hyperparameter grid presented in the model development methodology, where maximum tree count was capped at 400 and depth limitations were systematically evaluated. The computational constraint thus directly influenced the machine learning pipeline architecture, prioritizing model configurations that achieved acceptable predictive performance within the resource envelope defined by NFR1 and NFR3.
 
Table 13. Constraint analysis and design implications for GabayPalay mobile application development.
Constraint Category	Specific Limitation	Excluded Variables/Features	Design Response	Impact on System Architecture	Justification and Literature Support
Data Availability	Absence of local automated weather stations and limited farmer access to formal meteorological data in Hagonoy, Davao del Sur	Rainfall (mm), Temperature (°C), Wind Speed (m/s), Atmospheric Pressure (kPa), Solar Radiation—variables identified as statistically significant in related studies	Exclusive focus on farmer-observable and farmer-recordable inputs (X1-X27); Acceptance of upper bound on explainable variance; Emphasis on management-controllable factors	Feature set limited to 27 agronomic and management variables; Model training dataset excluded environmental covariates beyond binary weather challenge indicator (X27)	David, 2023 (environmental factors significant but require instrumentation); Dait, 2023 (rainfall and temperature effects); Stuecker et al., 2018 (climate variability impacts)
Computational	Mobile device processing limitations (2 GB RAM minimum); Android Studio compilation memory constraints; m2cgen code generation file size limits	Random Forest configurations with >400 trees; Unlimited tree depth; Ensemble sizes >500 estimators that produced Kotlin files >200 MB	Hyperparameter grid restricted to n_estimators ≤400, max_depth evaluated with practical ceiling; Tree pruning strategies if initial conversion exceeded compilation limits; Memory-efficient prediction traversal algorithms	Grid search parameter space constrained (Table methodology); Generated Kotlin model code optimized for mobile compilation and runtime execution; Prediction latency target ≤3 seconds on minimum-spec devices	NFR1 and NFR3 performance requirements; m2cgen library documentation on code generation scalability; Android resource management best practices


Table 12. (cont.)
Adoption	Zero baseline usage of farm-specific agricultural applications among all interview participants; Digital literacy gaps across farmer age ranges; Awareness not translating to sustained use in regional context	Complex multi-feature platforms; Cloud-dependent services; Social networking or community data-sharing modules; Integration with external agricultural databases requiring connectivity; Market price forecasting features	Focused core functionality emphasizing yield prediction (FR1) and transparent results (FR5); Streamlined interface with minimal cognitive load; Progressive disclosure hiding advanced features; Single-purpose tool optimized for planning and evaluation workflows	Three-screen primary workflow (input → review → predict); Elimination of non-essential features that increase interface complexity; Offline-first architecture removing connectivity as usage precondition; Multilingual support (NFR2) for immediate accessibility	Table 7 (I12: 11/11 non-usage); Angchay et al., 2024 (awareness-adoption gap in Davao del Sur); Gabrillo & Torres, 2022 (ICT tool benefits vs. uptake barriers)
Connectivity	Intermittent or absent mobile data and WiFi access in rural barangays; High cost of mobile data relative to farmer income; Infrastructure variability across study area	Real-time weather API integration; Cloud-based model inference; Online synchronization of prediction records; Remote database storage; Application updates requiring large downloads	Complete offline functionality for all core features (FR1); Local SQLite database persistence (FR6); Model embedded as compiled Kotlin code in APK; Manual update distribution via portable storage if needed	Entire Random Forest model converted and compiled into application binary; No network permission requests in Android manifest; Database encryption and local-only storage (NFR4)	Table 7 (I12: connectivity challenges); Angchay et al., 2024; regional infrastructure assessments showing inconsistent coverage in agricultural areas

Table 12. (cont.)
Economic	Input subsidy shortfalls creating mismatches between recommended and feasible fertilizer/seed quantities; Variable purchasing power across farm sizes; Cost sensitivity in input decisions	Rigid input recommendations assuming full subsidy access; Market-rate input cost calculations that might discourage usage; Integration with commercial input suppliers	Flexible input ranges accommodating observed variability (Table 8 fertilizer patterns; seed rate IQR 15-30 kg); Prediction model trained on actual farmer practice rather than idealized recommendations; Validation accepting zero values for optional inputs (e.g., third fertilizer application)	Input validation boundaries derived from survey quantiles rather than extension maxima; Model capable of prediction across full observed input space including resource-constrained scenarios	Table 9 (subsidy shortfalls response); Table 6 (farm size range 0.30-8.50 ha with differential access); Interview accounts of topping up subsidized inputs from private stores
Temporal	Seasonal decision-making rhythm with concentrated usage during pre-planting planning and post-harvest evaluation; Intermittent rather than daily tool engagement	Features assuming continuous engagement; Real-time monitoring dashboards; Frequent notification systems; Daily data entry requirements	Historical record persistence (FR6) supporting access to previous predictions after months of non-use; State preservation across application suspension and restart; No penalties for extended periods between sessions	Database design accommodating infrequent writes with long read-only periods; Application lifecycle management preserving partial inputs across device interruptions (NFR5); Update strategy not assuming regular connectivity checks	Table 8 (stage-based timing: basal at 3-10 DAT, top-dress at 15-30 and 45-60 DAT); Seasonal cropping pattern in Fig. 8; Decision support needs concentrated around planting windows

Table 12. (cont.)
Measurement Precision	Farmer recall and estimation for input quantities rather than precise weighing; Variable units of measurement (sacks vs. kg; sachets vs. liters); Approximations in area measurements	Assumptions of laboratory-grade measurement accuracy; Strict validation rejecting plausible estimate ranges; Requirement for GPS-based area measurement	Generous input validation ranges accepting estimate uncertainty; Conversion utilities for common farmer units (e.g., sacks to kg with regional bag weight assumptions); Tolerance for measurement imprecision in model training and prediction	Preprocessing pipeline (Appendix 4) standardizing reported fertilizer products to NPK equivalents; Validation boundaries set at 90th-95th percentiles of observed distributions rather than hard agronomic maxima	Interview accounts of experience-based quantity estimation; Table 8 fertilizer schedules showing product-level rather than nutrient-level reporting; Practical measurement constraints in field conditions
Technical Skill	Limited experience with form-based data entry; Potential confusion with agronomic terminology; Variable familiarity with smartphone interface conventions	Technical agricultural vocabulary without plain-language alternatives; Complex navigation requiring understanding of app structure; Assumption of familiarity with standard UI patterns (e.g., tabs, hamburger menus)	Plain-language labels with Bisaya translations (NFR2); Linear input flow minimizing navigation decisions; Contextual help text for potentially unfamiliar terms (e.g., NPK, days after transplanting); Visual indicators for required vs. optional fields	Interface design prioritizing explicit action buttons over gesture-based navigation; Single-path workflow through input stages; Error messages providing concrete corrective guidance rather than technical codes (NFR2, NFR5)	Table 7 (I12: digital literacy gaps); Angchay et al., 2024 qualitative findings on technology interaction challenges; Usability testing feedback during Phase 3 iterations
 
The adoption constraint recognized that zero baseline usage of farm-specific agricultural applications among interview participants (Table 7, I12) implied that GabayPalay could not assume any prior digital agricultural tool experience. This constraint elevated usability requirements (NFR2) to critical status and mandated extensive iterative refinement during the User Design phase (Phase 3). The adoption constraint also influenced functional requirement prioritization, emphasizing core prediction capability (FR1) and transparent result presentation (FR5) over ancillary features such as community data sharing or integration with external agricultural databases that, while potentially valuable, would increase interface complexity and connectivity requirements. The adoption barrier documented by Angchay et al. (2024) and Gabrillo and Torres (2022), where awareness of agricultural applications did not translate to sustained use, reinforced the requirement for a focused, immediately useful tool rather than a feature-rich platform that might overwhelm users during initial encounters.
The derived requirements, validated constraints, and established traceability framework provided the foundation for subsequent phases of the Rapid Application Development methodology. The specifications guided data processing and model development (Phase 2) by defining the exact input feature set, performance targets, and model conversion requirements. They directed user interface design and system architecture decisions (Phase 3) through explicit usability criteria, language support mandates, and modular organization principles. The requirements informed construction and implementation (Phase 4) by establishing acceptance criteria for unit testing and integration testing, and they shaped the comprehensive validation framework (Phase 5) by specifying the functional completeness, performance benchmarks, and user acceptance dimensions against which the completed GabayPalay application would be systematically evaluated. This requirements-driven development approach ensured that technical decisions throughout the project lifecycle remained grounded in the empirical understanding of Hagonoy rice farmers' practices, constraints, and decision-support needs documented during the requirements planning phase.
Model Development and Hyperparameter Optimization
Following the preprocessing procedures detailed in the methodology, the final dataset consisted of 54 farm records with 27 agronomic input features (X1 to X27) and one continuous target variable (palay yield in kg). All categorical variables were encoded as binary indicators, and fertilizer applications were standardized to total Nitrogen (N), Phosphorus (P₂O₅), and Potassium (K₂O) per application phase as described in Table 5 of the methodology.
The Random Forest Regressor was optimized through an exhaustive grid search spanning 216 unique hyperparameter combinations. Each configuration was evaluated using 3-fold cross-validation on the training set (n = 37 farms), with R² as the scoring metric. Table 1 presents both the search space explored and the optimal hyperparameters selected through systematic evaluation.
Table 14. Hyperparameter search space and optimal configuration selected through grid search cross-validation.
Hyperparameter	Search Space	Selected Value
n_estimators	[100, 200, 300, 400]	200
max_depth	[None, 10, 20]	10
min_samples_split	[2, 4, 6]	2
min_samples_leaf	[1, 2, 3]	1
max_features	['sqrt', 'log2']	'sqrt'

The grid search identified the optimal configuration that achieved a mean cross-validation R² of 0.604 with a standard deviation of ±0.104 across the three folds, indicating moderate variance due to the limited training sample size as discussed by James et al. (2023b). The selected hyperparameters balance model complexity and generalization capacity. The depth constraint of 10 levels prevents excessive overfitting while allowing sufficient tree complexity to capture nonlinear yield relationships identified in previous agricultural ML studies (David, 2023; Prasath et al., 2023). The square root feature selection at each split introduces appropriate randomness to decorrelate individual trees, enhancing ensemble diversity as described by Breiman (2001). The complete grid search results, including all 216 configurations with their respective cross-validation and test set performance metrics, are documented in Appendix X.
Hold-out test set validation
The optimized Random Forest model, trained on 37 farms (70% of the dataset) following the train-test split methodology recommended by James et al. (2023b), was evaluated on a held-out test set of 17 farms (30%) that were completely excluded from all training and hyperparameter selection procedures. The model achieved strong predictive performance on this independent validation set, as summarized in Table 2.
Table 15. Performance metrics of the optimized Random Forest model on the hold-out test set (n=17 farms).
Metric	Value
R² (coefficient of determination)	0.765
RMSE (root mean squared error)	2,286 kg
MAE (mean absolute error)	1,731 kg
MSE (mean squared error)	5,225,794 kg²

The test set R² of 0.765 indicates that the model explains approximately 76.5% of yield variance in farms it has never encountered during training, demonstrating strong generalization capacity. This performance is comparable to or exceeds results reported in similar rice yield prediction studies, as shown in Table 3 from David (2023), where Random Forest achieved test R² of 0.647 on rice yield prediction in Pampanga River Basin, while ANN showed test R² of 0.365 and Linear Regression achieved 0.572. To contextualize these error metrics, farm-level palay yield in the complete dataset showed a median of 6,287 kg with values ranging from 1,220 kg (lowest performing farm) to 20,790 kg (highest performing farm), indicating substantial variability in productivity across the sample. The RMSE of 2,286 kg represents approximately 36% of the median yield, indicating reasonable predictive accuracy across diverse farming conditions. The lower MAE relative to RMSE (1,731 vs. 2,286 kg) suggests that while most predictions are close to actual values, a few larger errors contribute disproportionately to the squared error metric, consistent with the heterogeneous nature of agricultural yields as noted by Yang et al. (2016).
As illustrated in Fig. 1, points cluster moderately around the 1:1 diagonal line, with tighter agreement in the mid-yield range (5,000 to 15,000 kg) and greater dispersion at the extremes. Several test cases exhibit residuals exceeding ±3,000 kg, suggesting that certain farm-specific conditions or input combinations present greater prediction challenges. Nonetheless, the overall pattern demonstrates that the model generalizes reasonably to unseen farms without severe systematic bias, supporting the Random Forest approach's suitability for rice yield prediction identified by Jiya et al. (2023).
 
Fig. 26. Predicted versus actual yield for the hold-out test set (n=17 farms).
The dashed red line represents perfect 1:1 agreement between predictions and observations. Points are scattered around the diagonal with R²=0.765, RMSE=2,286 kg, and MAE=1,731 kg, reflecting the model's generalization capacity to farms excluded from training. The scatter pattern aligns with expected model behavior on unseen data, with moderate clustering around the diagonal and acceptable deviation ranges.
Fig. 2 displays the residual plot for the test set, showing the distribution of prediction errors across the range of predicted yields. Residuals are scattered relatively randomly around the zero line without strong evidence of systematic bias or heteroscedasticity, although several outliers exceed ±4,000 kg. The absence of clear patterns in the residuals indicates that the model does not consistently over- or under-predict across the yield spectrum, supporting the validity of the Random Forest approach for this application as demonstrated in similar agricultural studies (Prasath et al., 2023).
 
Fig. 27. Residual plot for the hold-out test set (n=17 farms).
Residuals (actual minus predicted yield) are plotted against predicted values. The horizontal red dashed line at zero represents perfect prediction. Random scatter without strong patterns indicates no systematic bias, though several outliers suggest that extreme farming conditions remain challenging to predict. This residual distribution is consistent with heterogeneous agricultural data where localized factors may influence individual farm outcomes.
Model performance across the complete dataset
To visualize the model's behavior across the full observed yield range and to distinguish in-sample fit from out-of-sample generalization, Fig. 3 presents predicted versus actual yields for all 54 farms with training and test samples color-coded. Training samples (n=37, blue circles) cluster more tightly around the 1:1 diagonal due to the model having learned their patterns during optimization. Test samples (n=17, orange circles) exhibit greater dispersion, as expected for predictions on farms never encountered during training. When predictions for both sets are aggregated, the combined apparent R² is 0.882; however, this metric is descriptive only as it mixes in-sample and out-of-sample performance following the validation framework established by Kuhn and Johnson (2013). The test set R²=0.765 remains the credible estimate of generalization to new farmers.
The color-coded visualization demonstrates that the model maintains reasonable predictive capacity across the observed yield spectrum from 1,220 to 20,790 kg. Both training and test samples span this range, indicating that the 70-30 random split preserved adequate representation of diverse yield conditions in both subsets. The visual distinction between tight in-sample fit (blue) and more scattered out-of-sample predictions (orange) provides transparent communication of model performance and confirms that the model is not severely overfitting, as test points remain reasonably close to the diagonal despite not being used for training. This pattern aligns with Random Forest's ensemble approach that balances bias and variance through bootstrap aggregation as described by Breiman (2001).
  
  (a)                                                                  (b)
Fig. 28. Predicted versus actual yield (a) and residual plot (b) for the complete dataset (n=54 farms), with training and test sets color-coded.
Fig. 4 extends the residual analysis to all 54 farms, maintaining the color-coded distinction between training (blue) and test (orange) samples. Training residuals are generally smaller in magnitude and more evenly distributed around zero, consistent with the model's direct exposure to these cases during learning. Test residuals exhibit greater variance and include several outliers beyond ±4,000 kg, reinforcing that predicting unseen farms presents inherent challenges common in agricultural prediction systems (Yang et al., 2016). The overall pattern across both subsets shows no strong systematic trends, supporting the model's suitability for deployment despite the larger errors observed in a subset of test cases. 
Table 3 summarizes the apparent performance metrics when the model trained on 37 farms is applied to the entire dataset of 54 farms. As expected, these combined metrics are superior to the test-only metrics due to the inclusion of the 37 training samples on which the model was optimized, consistent with the expected behavior of machine learning models on mixed training and test data (Hastie et al., 2009). These values are reported for descriptive completeness but do not represent independent validation. The test set metrics in Table 2 remain the primary benchmark for expected real-world performance on new farmers.
Table 16. Apparent performance metrics when the model trained on 37 farms is applied to the complete dataset (n=54 farms).
Metric	Value
R²	0.882
RMSE	1,560 kg
MAE	1,056 kg
MSE	2,435,273 kg²


Model export and parity validation
The validated Random Forest model was exported to Java using the m2cgen library to enable integration with the GabayPalay Android application, following the machine learning pipeline architecture established by Google (2024) for production deployment. The export process converted the entire ensemble of 200 decision trees, including all split thresholds, feature indices, and leaf values, into a standalone Java class that can execute predictions without requiring external ML libraries or network connectivity. This architecture ensures that farmers can obtain yield predictions offline in real time directly on their mobile devices, addressing the connectivity challenges identified by Angchay et al. (2024) among farmers in Davao del Sur.
To verify the numerical fidelity of the conversion process, a comprehensive parity test was conducted comparing predictions from the original Python scikit-learn model against the m2cgen-generated Java implementation. The detailed methodology and code implementation for this parity test are provided in Appendix X. The parity test evaluated all 17 held-out test samples, computing the absolute difference and relative error between Python and Java predictions for each case. As documented in Table 4, the Java implementation achieved perfect numerical agreement with the Python baseline across all test cases, with zero absolute difference (0.00 kg) and zero relative error (0.0000%) for every prediction. 
Table 17. Summary statistics from the parity test comparing Python (scikit-learn) and Java (m2cgen) predictions on the 17 test samples.
Statistic	Absolute Difference (kg)	Relative Error (%)
Mean	0.00	0.0000
Standard Deviation	0.00	0.0000
Maximum	0.00	0.0000
Minimum	0.00	0.0000
These results confirm that the m2cgen export process faithfully preserved the complete model structure without introducing rounding errors, numerical drift, or implementation bugs, ensuring prediction consistency across platforms. The perfect parity results validate the technical readiness of the Java model for deployment in the Android application. Farmers using the GabayPalay app can trust that the predictions generated on their devices are mathematically identical to those produced by the validated Python model, ensuring consistency and reliability across platforms as required for production machine learning systems (Google, 2024).
The optimized Random Forest Regressor, trained on 37 farms and validated on 17 held-out farms, achieved a test set R² of 0.765 with RMSE of 2,286 kg and MAE of 1,731 kg, representing the expected predictive accuracy for new farmers not included in the training data. This performance exceeds results reported in similar rice yield prediction studies, particularly the test R² of 0.647 achieved by David (2023) using Random Forest on comparable agricultural data, demonstrating the model's effectiveness for the local context of Hagonoy, Davao del Sur. Hyperparameter optimization via exhaustive grid search identified 200 estimators with maximum depth of 10 as the best configuration, balancing model complexity and generalization capacity according to established Random Forest principles (Breiman, 2001). The model was successfully exported to Java with perfect numerical parity validated across all test cases, enabling reliable offline deployment in the GabayPalay Android application and addressing technology adoption barriers identified among Filipino rice farmers (Angchay et al., 2024).


Mobile Application Development and Deployment
Following successful completion of the requirements planning and model development phases, the construction and implementation phase translated the derived functional and non-functional requirements (Table 11) into a working mobile application. This section presents the results of RAD Phase 3 (Construction and Implementation), documenting the application architecture, feature implementation status, user interface design, and technical validation procedures that confirmed all specified requirements were successfully met or appropriately adapted based on technical constraints encountered during development.
Application architecture and feature implementation
The GabayPalay mobile application was successfully developed and deployed using Android Studio with Kotlin as the primary programming language. The application targeted Android 8.0 (API level 26) and above to ensure broad device compatibility among the target farmer population in Hagonoy, Davao del Sur, directly addressing Requirement NFR1 (Device Compatibility and Resource Optimization) specified in Table 11. The validated Random Forest model, converted to Java using the m2cgen library with perfect numerical parity as documented in Table 16, was integrated into the application to enable offline yield prediction functionality (Requirement FR1) without internet dependency.
The application architecture implemented a three-layer modular design consisting of the user interface layer, business logic layer, and data persistence layer, following Android development best practices (Android Developers, 2025). This separation of concerns facilitated systematic testing of individual components and supported the iterative development cycles characteristic of the RAD methodology. Local data storage was implemented using Android's Room Persistence Library, an abstraction layer over SQLite that provides compile-time verification of SQL queries and simplified database operations (Android Developers, 2024a). The Room database stores two entity types: PredictionHistoryEntity (containing prediction ID, predicted yield, confidence score, timestamp, and favorite flag) and PredictionInputEntity (containing all 27 farm input features X1-X27 associated with each prediction). This architecture supported offline functionality and historical record management (Requirement FR6: Historical Prediction Record Management) while maintaining data exclusively on the user's device, addressing the privacy concerns expressed during the informed consent process (Appendix 1) and the connectivity constraints documented in Table 12.
The m2cgen library generates the trained Random Forest model as a Java class file consisting of nested conditional statements representing the 200 decision trees. While the GabayPalay application was developed primarily in Kotlin, the model was retained as Java rather than manually converting to Kotlin due to Java-Kotlin interoperability in Android projects (JetBrains, 2023). Kotlin code can directly invoke Java classes without modification or performance penalty, as both compile to the same JVM bytecode. Attempting to convert the m2cgen-generated Java file to Kotlin would have introduced several technical risks: (1) file size limitations in automated conversion tools, as the generated Model.java exceeds 10,000 lines due to the explicit encoding of 200 trees with max_depth = 10; (2) potential introduction of conversion errors in the complex nested conditional logic that could compromise prediction accuracy; and (3) loss of the direct validation chain from the Python scikit-learn model through m2cgen to Java, requiring 
 
re-validation of a Kotlin conversion. The decision to maintain Java for the model class while using Kotlin for all application code followed Android development best practices for polyglot projects (Android Developers, 2023), where performance-critical or tool-generated components remain in their native language.
Functional requirements implementation status
All six functional requirements derived from the empirical analysis of farmer practices and needs (Table 11) were successfully implemented and validated through systematic functional testing procedures. Table 17 summarizes the implementation status, technical approach, and validation evidence for each functional requirement.
Table 18. Functional requirements implementation status and validation evidence.
Requirement ID	Requirement Description	Implementation Status	Technical Implementation	Validation Evidence
FR1	Offline yield prediction capability	Implemented	Java-converted Random Forest model integrated via m2cgen (200 trees, max_depth=10); Room database local storage; no network permissions in AndroidManifest.xml	Functional testing confirmed prediction execution in airplane mode; Informal performance observations indicated consistently rapid response with no user complaints during UAT (n=36)
FR2	Stage-based agricultural input management	Implemented	Three-phase fertilizer input forms (Basal, Mid-season, Late-season) with dynamic field generation based on split selection (1-3 applications); Automatic NPK calculation from fertilizer type and quantity	Nutrient Management UI (Figure 31); Unit test validation of NPK calculation against preprocessing logic; Support for 5 common fertilizer formulations identified in Table 8
Table 17. (cont.).
FR3	Rice variety classification and seed rate management	Implemented	Binary dropdown selector (Hybrid/Inbred) mapped to X2; Numeric input field for seed quantity with validation range 15-40 kg/ha based on observed distribution (Table 10: median seed rate 25 kg)	Pre-planting form (Figure 30); Input validation prevents out-of-range entries and displays error messages (Figure 30b)
FR4	Pest, disease, and water management recording	Implemented	Checkbox groups for 5 pest/disease categories (X18-X22: stem borer, rats, kuhol, cutworms, rice blast) aligned with Table 7 themes I5-I6; Numeric inputs for 4 pesticide types (X23-X26); Binary weather challenge indicator (X27)	Pest Management UI (Figure 32a-b); Weather UI (Figure 32c); Checkbox state persistence verified through activity lifecycle testing
FR5	Transparent prediction result presentation	Implemented	Prediction display in kilograms with conversions to cavans (÷50) and sacks (÷50); Feature importance chart showing top 10 contributors using impurity-based importance from trained model; Clear visual hierarchy with primary result emphasized	Results screens (Figures 33b-d, 34); Chart renders correctly on devices with varied screen densities (tested during development and UAT)
FR6	Historical prediction record management	Implemented	Room database with DAO-based CRUD operations; Prediction entity schema includes timestamp, farm inputs (X1-X27), predicted yield, and favorite flag; Recent predictions (chronological) and Favorites tabs; Indexed queries on timestamp and favorite status	History UI (Figure 35); Database persistence verified through app restart tests during development; Tested with multiple saved predictions during UAT (n=36 farmers)
UAT = User Acceptance Testing. 
The offline prediction capability (FR1) was implemented by embedding the m2cgen-generated Java model class directly into the application package, eliminating all external dependencies. This approach ensured that yield predictions could be generated on-device without network connectivity, addressing the universal absence of agricultural application usage documented in Table 7 (Theme I12, 100% of interview participants, n=11) and the connectivity constraints identified in Table 12. Functional testing confirmed that predictions executed successfully with all network interfaces disabled (WiFi and mobile data in airplane mode), validating the offline capability. Informal performance observations during development and user acceptance testing indicated that prediction execution was consistently rapid, with no perceptible delay between user input submission and result display. The subjective immediacy of the response satisfied the ≤3 seconds performance target specified in NFR3, as no farmers during UAT (n=36) reported delays or expressed concerns about application responsiveness.
The stage-based input management (FR2) directly addressed the universal 2-3 phase fertilization pattern documented in qualitative interviews (Table 7, Theme I9: 100% of participants) and quantitative surveys (Table 8: typical timing patterns). The implementation allowed farmers to specify one, two, or three fertilizer applications through a dropdown selector, which dynamically generated the appropriate number of input sections. For each application, farmers entered the fertilizer type (selected from five common formulations: Urea 46-0-0, Ammonium Sulfate 21-0-0, Ammonium Phosphate 16-20-0, Complete 14-14-14, Muriate of Potash 0-0-60), the quantity applied, and the unit of measurement (kilograms or 50-kg sacks). The application automatically converted sack measurements to kilograms and computed total NPK values (X9-X17) using the preprocessing logic validated during model development, ensuring consistency between training data transformations and production inference inputs.
The selection of hectares for land area and kilograms for seed and yield measurements was grounded in the observed practices documented during the quantitative survey. All 54 respondents reported land area in hectares (Table 10: median 1.00 ha, IQR 0.75-2.00 ha), consistent with the metric system adopted by Philippine agriculture under the Revised Administrative Code of 1987 (Republic of the Philippines, 1987) and reinforced by the Agriculture and Fisheries Modernization Act (AFMA) of 1997 (Republic Act No. 8435, 1997), which standardized land measurement reporting in hectares for agricultural statistics. Similarly, seed rates were universally reported in kilograms (Table 10: range 15-40 kg), aligning with commercial seed packaging standards used by certified seed producers in the Philippines.
Yield was captured in kilograms to match the model's training data unit and to provide precision for small farm operations where sack-based rounding (50 kg increments) could mask productivity differences. However, recognizing that farmers traditionally conceptualize yields in cavans (50 kg per cavan, a traditional Philippine rice measurement unit) and sacks (the commercial packaging standard), the results interface (Figure 33c) automatically converted kilogram predictions to these familiar units. This dual-unit presentation balanced scientific precision (model output in kg) with practical utility (cavan/sack conversions for farmer decision-making), as documented in qualitative interviews where farmers referenced both "sacks per hectare" and "cavans per area" when discussing historical yields (Table 6).
Rice variety classification (FR3) was implemented as a binary dropdown offering "Hybrid" and "Inbred" options, mapped to the X2 feature (1 = Hybrid, 0 = Inbred). This classification reflected the observed distribution in Table 10 (83.3% hybrid, 16.7% inbred) and the qualitative theme of hybrid preference constrained by cost and availability (Table 7, Theme I10: 7/11 farmers). Seed rate input validation enforced the range of 15-40 kg/ha based on the observed distribution in the quantitative survey, preventing entry of implausible values while accommodating the full spectrum of reported practices.
Pest and disease management recording (FR4) implemented checkbox groups for the five key challenges identified through thematic analysis (Table 7: stem borer I5, rats I6, golden apple snail via molluscicide theme I3) and additional common rice pests documented in the literature (Heinrichs, n.d.). The interface design emphasized preventive timing through visual cues and contextual help text, aligning with the IPM orientation documented in Theme I4 (10/11 farmers reported limited routine insecticide use). Weather challenge recording captured the binary presence indicator (X27) that emerged as relevant during data analysis, despite the counterintuitive yield patterns noted in the quantitative findings’ discussion.
Transparent prediction result presentation (FR5) addressed trust concerns and interpretation challenges identified during requirements planning. The results interface displayed the predicted yield prominently in kilograms (the model's native output unit), with automatic conversions to cavans and sacks to provide familiar reference points for farmers. The detailed results view incorporated a horizontal bar chart visualizing feature importance score for all 27 input variables, ranked in descending order of contribution to the prediction. This interpretability component addressed the "black box" concern common
 
in machine learning applications, enabling farmers to understand which agronomic factors strongly influenced their specific yield estimate.
Historical prediction record management (FR6) implemented persistent local storage using Room Persistence Library, enabling farmers to save prediction sessions, review past estimates, and compare different input scenarios over time. This capability supported the experience-based, longitudinal decision-making mode documented in Table 7 (Theme I13) and reinforced by farmers' decades of experience (Table 6: range 3-40+ years). The favorites feature allowed bookmarking of frequently referenced configurations, facilitating quick access to baseline scenarios for sensitivity analysis.
Non-functional requirements validation
All five non-functional requirements were successfully validated through systematic testing procedures conducted during the construction phase, though several requirements were met through adapted approaches based on technical constraints and development timeline considerations. Table 18 presents the target specifications, measured or observed performance, validation methods, and achievement status for each non-functional requirement.
The device compatibility requirement (NFR1) was validated through functional testing during development and user acceptance testing with 36 farmers who used their personal smartphones representing diverse device configurations typical of the target population. The zero crash reports and absence of compatibility failures during these UAT sessions provided empirical evidence that the application operated successfully across the range of devices owned by farmers in Hagonoy, Davao del Sur. The application's modest APK size (12.4 MB) fell well below the 50 MB target established during requirements 
 
derivation (Table 11, NFR1), enabling distribution via Bluetooth transfer and social media messaging platforms to accommodate the connectivity constraints documented in Table 12. The application's resource efficiency was demonstrated by the consistent absence of out-of-memory errors during all testing sessions, though systematic memory profiling using Android Studio's Memory Profiler was not conducted as part of the formal validation protocol.
Table 19. Non-functional requirements validation results.
Requirement ID	Requirement Description	Target Specification	Measured/Observed Performance	Validation Method	Achievement Status
NFR1	Device compatibility and resource optimization	Android ≥8.0 (API 26); APK size ≤50 MB; RAM usage ≤150 MB during active use; Graceful performance on 2 GB RAM devices	APK size = 12.4 MB (75% below target); No out-of-memory errors reported during UAT (n=36 farmers using personal devices); Consistent functionality observed across diverse farmer-owned smartphones	APK size measurement via Android Studio Build Analyzer; Functional testing during development; UAT with 36 farmers using their personal smartphones	Met (via UAT validation; systematic device testing not conducted)
NFR2	Usability and multilingual accessibility	Simplified UI for low digital literacy; English/Bisaya bilingual labels; Clear visual hierarchy; Contextual help; SUS target ≥70 (acceptable usability)	English-only labels implemented; Bisaya deferred due to timeline constraints; Visual Getting Started guide provided; Simplified navigation; SUS mean score = 73.5 (Good usability per Brooke 1996)	User acceptance testing (n=36 farmers); SUS questionnaire administration; Qualitative feedback collection during guided sessions	Partially Met (English only; usability target achieved)

Table 18. (cont.).
NFR3	Prediction performance and response time	Prediction execution ≤3 seconds from input submission to result display; ≥99% numerical parity with Python baseline model	Informal observations: consistently rapid response with no perceptible delays; 100% perfect parity across all 17 test samples (Table 16); No performance complaints during UAT (n=36)	Informal performance observations during development and UAT; Parity test comparing Java output to Python scikit-learn predictions (Appendix X); User feedback during UAT sessions	✓ Met (via informal validation; formal timing not conducted)
NFR4	Data security and privacy protection	Local database storage with encryption; No external data transmission; Secure storage of farm inputs and prediction history	Room Persistence Library (SQLite); Database in app-private directory; Zero network permissions in AndroidManifest.xml; No network library dependencies; All data remains on device; Encryption deferred (OS-level sandbox security instead)	Code review of AndroidManifest.xml and build.gradle; Functional verification of offline operation; Review of Room database implementation; Informed consent compliance check	✓ Met (via OS-level isolation and offline architecture; encryption not implemented)
NFR5	System reliability and error resilience	Consistent predictions across device configurations; Zero crashes during testing; Graceful error handling for invalid inputs; Recovery from unexpected states	Zero crashes during development testing; Zero crash reports during UAT (n=36 farmers); Input validation prevents invalid submissions; State persistence during activity lifecycle events observed during UAT	Development testing during iterative construction; UAT observation with 36 farmers; Informal boundary testing during development; User feedback on error handling	✓ Met (via development testing and UAT; formal test cases not documented)
 

The usability and multilingual accessibility requirement (NFR2) was partially met with adaptations based on development timeline constraints. The application user interface was developed with English-only labels and instructions, although the initial requirements specification (NFR2, Table 11) included bilingual accessibility (English/Bisaya). During the construction phase, technical constraints related to Android localization resource management and development timeline prioritization led to implementing only English strings in the res/values/strings.xml file. The decision to defer multilingual support was based on development timeline prioritization, where English-only implementation was completed to ensure core functionality (FR1-FR6) met the thesis deadline. The application's string resources were externalized to Android's strings.xml resource file following standard localization practices (Android Developers, 2024b), positioning the application for straightforward Bisaya translation in future iterations through creation of a locale-specific resource file (values-ceb/strings.xml) without requiring code modification.
The English-only implementation still satisfied the core usability requirement for the target population, as all interview participants (n=11) and survey respondents (n=54) demonstrated functional English literacy sufficient to complete the survey instruments (Appendix 3) and engage with the research protocol. Additionally, the application's simplified visual design, recognizable iconography, and contextual help (Getting Started guide, Figure 29c) reduced text dependency, supporting users through visual affordances rather than language-heavy instructions. The System Usability Scale assessment (detailed in the User Acceptance Testing section) yielded a mean score of 73.5, exceeding the acceptability threshold of 70 established by Brooke (1996) and confirming that the English-only interface achieved "Good" usability despite the absence of Bisaya translation.
The prediction performance requirement (NFR3) specified completion within 3 seconds to maintain user engagement and provide responsive feedback during the input workflow. Formal systematic timing measurements across controlled trials were not conducted within the thesis scope, but informal performance observations during development and user acceptance testing indicated that prediction execution was consistently rapid, with no perceptible delay between user input submission and result display. The subjective immediacy of the response satisfied the target threshold, as no farmers during UAT (n=36) reported delays or expressed concerns about application responsiveness. The 100% perfect numerical parity with the Python baseline model (Table 16: zero absolute difference across all 17 test samples) confirmed that the Java implementation produced mathematically identical predictions, satisfying the ≥99% parity specification with zero tolerance for rounding errors or implementation discrepancies.
Data security and privacy protection (NFR4) were validated through code review and functional verification rather than formal security audit procedures. The application codebase was reviewed to confirm the absence of network-related Android permissions in the AndroidManifest.xml file (no INTERNET, ACCESS_NETWORK_STATE, or ACCESS_WIFI_STATE permissions declared) and the absence of network library dependencies in the application's build.gradle configuration (no Retrofit, OkHttp, Volley, or similar HTTP client libraries included). Manual verification during application testing confirmed that no network connectivity was required or utilized at any stage of the prediction workflow, from data input through result display to history management.
The database implementation used Android's Room Persistence Library, which provides compile-time verification of SQL queries, type-safe database access, and simplified database operations compared to raw SQLite (Android Developers, 2024a). The Room database stores all farm data (inputs X1-X27, prediction results, timestamps) in the application's private data directory, protected by Android's application sandbox security model where each app's private data is accessible only to the app's process. While the initial requirements specification (Table 11, NFR4) included database encryption as a security mechanism, the implemented solution used Room's built-in SQLite storage with Android OS-level sandbox protection instead. This architectural decision was made during the construction phase based on several considerations: (1) sufficient privacy protection through the Android application sandbox, where each app's private data directory is accessible only to the app's process; (2) avoidance of native library dependencies that could introduce compatibility issues across the diverse Android versions (8.0-13.0) targeted for deployment; and (3) performance considerations for low-specification devices (2 GB RAM minimum) where encryption overhead could impact responsiveness.
This approach satisfied the core privacy requirement—farmer data never leaves the device and is inaccessible to other applications—while avoiding the dependency overhead, potential compatibility issues, and performance impact associated with native encryption libraries such as SQLCipher. The Room Persistence Library additionally provided type-safe database access through compile-time SQL query validation (Android Developers, 2024a), reducing the risk of runtime database errors that could compromise data integrity. This implementation satisfied the privacy assurances provided in the informed consent form (Appendix 1), where participants were explicitly informed that "all data remains on your device and will not be transmitted to any external server" (Appendix 1, Part I: Information Sheet).
System reliability and error resilience (NFR5) were validated through iterative development testing and user acceptance testing rather than formal systematic test case execution. During the construction phase, the application was tested through iterative development cycles to verify functional consistency and identify potential crash conditions. User acceptance testing with 36 farmers provided real-world validation of application stability under authentic usage conditions. Participants completed full prediction workflows from data input through result viewing and history management, with zero crash reports or application failures documented during the testing sessions. Several participants made input corrections by navigating backward through the four-stage input process, and others interrupted the prediction workflow to answer phone calls or switch to other applications before returning to complete their predictions. The application correctly maintained state and allowed workflow resumption in all observed cases, demonstrating resilience to typical Android activity lifecycle events (backgrounding/foregrounding, screen rotation, app switching).
Input validation mechanisms prevented submission of incomplete or invalid data through field-level validation with contextual error messages (Figure 30b: empty required field highlighted with red border and adjacent error text). The validation logic enforced reasonable ranges for numeric inputs based on the observed data distribution in the quantitative survey (e.g., land area >0 hectares, seed rate 1-100 kg to accommodate the documented range of 15-40 kg with margin for outliers). Informal boundary testing during development confirmed that the application handled edge cases (very small land areas, zero fertilizer applications, maximum pest selections) without crashes, though systematic edge case documentation through formal test plans was not conducted within the thesis development timeline.
Application user interface design
The GabayPalay application user interface was designed to prioritize simplicity, accessibility, and alignment with farmer mental models, directly addressing Requirement NFR2 (Usability and Multilingual Accessibility) and the documented digital literacy challenges (Table 7, Theme I12: 100% non-usage of agricultural applications; Table 11, NFR2 rationale). The interface employed a simplified interaction model with clear visual hierarchy, recognizable iconography, and English labels throughout all screens to accommodate the literacy levels and language proficiency observed in the target population. While bilingual (English/Bisaya) support was initially specified, the English-only implementation was complemented by visual design elements that reduced text dependency, including icons, color coding, and a visual Getting Started guide.
The main navigation and core screens are illustrated in Figures 29-35, demonstrating the visual design language, information architecture, and interaction patterns implemented to support farmers through the complete prediction workflow from initial application launch to result interpretation and historical record management.
(insert pics here)
Figure 29. GabayPalay application splash screen and home interface. (a) Splash screen displaying application branding and tagline during initialization (typical display duration 1-2 seconds). (b) Home screen providing primary navigation buttons to "Predict Palay Yield" (main feature) and "View History" (secondary feature), with recognizable icons and concise English labels. (c) Getting Started guide offering visual step-by-step walkthrough of the prediction workflow for first-time users, accessible via help icon on home screen.
The home screen (Figure 29b) implemented a minimal navigation model with two large, tappable buttons corresponding to the primary use cases identified during requirements planning: generating a new yield prediction and reviewing historical predictions. The visual design employed high contrast (dark text on light background), generous touch target sizes (minimum 48×48 dp per Android accessibility guidelines), and clear visual affordances (raised button appearance with shadow cues) to support users with limited smartphone experience. The Getting Started guide (Figure 29c) provided optional onboarding for new users, offering a visual walkthrough of the four-stage input process without requiring text-heavy instruction.
The data input workflow was organized into four sequential stages, each presented on a dedicated screen with focused content and clear navigation controls. This staged approach prevented cognitive overload by presenting only the subset of inputs relevant to each phase of the rice production process, aligning with the stage-based mental model documented in farmer interviews (Table 8: typical timing patterns) and directly implementing Requirement FR2 (Stage-Based Agricultural Input Management).
(insert pics here)
Figure 30. Pre-planting data input interface implementing Requirement FR3. (a) Input form displaying fields for land area (hectares), rice variety selection (binary dropdown: Hybrid/Inbred), seed amount (kilograms), planting method (binary dropdown: Transplanted/Direct Seeded), land preparation techniques (checkbox group: Manual, Tractor, Rotavator), and irrigation source (binary: NIA irrigation yes/no). (b) Error validation feedback highlighting incomplete required fields (red border on land area input) and displaying contextual error message ("Please enter land area"), demonstrating Requirement NFR5 (Error Resilience) through graceful error handling and clear user guidance.
The pre-planting interface (Figure 30) collected fundamental farm characteristics that establish the baseline context for yield prediction. The rice variety dropdown implemented Requirement FR3, offering the binary classification (Hybrid/Inbred) that reflected both the observed distribution (Table 10: 83.3% hybrid) and the qualitative preference pattern constrained by economic factors (Table 7, Theme I10). Seed rate input validation enforced the 15-40 kg/ha range derived from the quantitative survey distribution, displaying a clear error message if farmers attempted to enter values outside this empirically grounded range. Land preparation checkboxes supported multiple selections (e.g., both Tractor and Rotavator used sequentially), accommodating the diverse operational approaches documented in Table 6.
The error validation approach (Figure 30b) implemented Requirement NFR5 by preventing form submission with incomplete data while providing clear, non-technical guidance to farmers about which fields required attention. The visual feedback (red border on invalid fields, adjacent error text) and prevention of forward navigation until validation passed reduced frustration and data entry errors compared to allowing submission followed by rejection.
(insert pics here)
Figure 31. Nutrient management input interface implementing Requirement FR2. (a) Initial screen prompting selection of number of fertilizer application splits (2 or 3), corresponding to the observed fertilization patterns in Table 8. (b) Dropdown menu displaying the two split options with clear labels. (c) Empty input fields dynamically generated after selecting "3 splits," showing the three application sections ready for data entry. (d) Unit selection dropdown for fertilizer quantity, offering "Kilograms (kg)" option. (e) Alternative unit selection showing "Sacks (50 kg/sack)" option to accommodate traditional measurement practices. (f) Completed fertilizer inputs demonstrating all three applications filled with varied NPK formulations (14-14-14, 46-0-0, 0-0-60) representing typical basal and topdressing patterns from Table 8.
The nutrient management interface (Figure 31) represented the most complex input stage, accommodating the universal but variable-timing fertilization practices documented in 100% of farmer interviews (Table 7, Theme I9) and detailed in Table 8. The implementation of Requirement FR2 through dynamic form generation based on split selection (Figure 31a-c) directly addressed the 2-3 phase pattern while maintaining interface simplicity by showing only the relevant input sections. For each application, farmers selected from five fertilizer types identified as common in the Hagonoy context: Complete (14-14-14), Urea (46-0-0), Ammonium Sulfate (21-0-0), Ammonium Phosphate (16-20-0), and Muriate of Potash (0-0-60). These formulations covered the fertilizer products explicitly mentioned in farmer interviews (Table 6, Table 8) and enabled automated NPK calculation without requiring farmers to understand or enter nutrient composition directly.
The unit selection feature (Figure 31d-e) addressed the measurement variability documented during requirements planning, where farmers reported quantities in both kilograms and sacks (50 kg per sack being the standard local packaging). The application automatically converted sack inputs to kilograms during data processing, then computed total N, P₂O₅, and K₂O values for each application phase using the NPK ratios declared for each fertilizer type. This automated calculation eliminated manual computation burden while ensuring that the feature vector (X9-X17) presented to the Random Forest model matched the preprocessing transformations applied during training, maintaining the validated model's prediction accuracy.
(insert pics here)
Figure 32. Pest management and weather condition input interfaces implementing Requirement FR4. (a) Blank pest management form displaying checkbox groups for five common pests and diseases (stem borer, rats, golden apple snail/kuhol, cutworms, rice blast) aligned with Table 7 themes I5-I6 and literature on key rice pests (Heinrichs, n.d.), plus numeric input fields for four pesticide type quantities (insecticide in liters, herbicide in liters, rat poison in grams, molluscicide in sachets). (b) Completed pest management inputs showing selected pests (stem borer, kuhol, rice blast) and applied pesticide amounts. (c) Weather conditions interface with binary checkbox for weather-related challenges (drought, flooding, typhoon, temperature extremes), capturing the X27 feature that emerged during data analysis.
The pest management interface (Figure 32a-b) implemented Requirement FR4 through a simplified binary presence model for each pest category, reflecting the approach used during model training where pest indicators were encoded as binary features (X18-X22: 1 = present, 0 = absent). The checkbox design enabled farmers to quickly indicate which pests affected their farm during the season without requiring quantitative damage assessment or incidence percentages, which would have been difficult to estimate accurately. The pesticide quantity inputs used units aligned with local product packaging: liters for liquid insecticides and herbicides, grams for solid rat poison baits, and sachets for molluscicide products typically sold in pre-measured packets. This attention to measurement unit realism reduced cognitive translation burden and improved data entry accuracy.
The weather conditions screen (Figure 32c) captured the binary weather challenge indicator (X27) through a straightforward checkbox. While the quantitative analysis revealed counterintuitive yield patterns for this variable (farmers reporting weather challenges achieved higher median yields than those reporting none), the feature was retained in the model based on its potential interactions with other variables and its theoretical significance documented in related literature (David, 2023; Dait, 2023; Stuecker et al., 2018). The simple binary representation (challenges present or absent) avoided requiring farmers to quantify or categorize specific weather impacts, which would have introduced measurement complexity and reduced completion rates.
(insert pics here)
Figure 33. Input review and prediction results interfaces implementing Requirement FR5. (a) Review modal displaying comprehensive summary of all farm inputs organized by category (Pre-planting, Nutrient Management, Pest Management, Weather), with "Edit" button enabling return to previous screens for corrections and "Confirm & Predict" button initiating model execution. (b) Simple prediction results screen showing the estimated yield prominently displayed in large text (8,450 kg) with visual emphasis, plus action buttons for viewing detailed analysis or saving to history. (c) Detailed results view showing predicted yield with automatic conversions to familiar units (cavans and sacks), enabling practical comparison to historical yields and market transactions. (d) Expanded detailed view including horizontal bar chart visualizing feature importance scores for top factors influencing the prediction, implementing the transparency component of FR5.
The input review interface (Figure 33a) provided farmers with a final verification opportunity before executing the prediction, addressing the common user challenge of needing to "go back and correct mistakes" documented during user acceptance testing (27.8% of participants, n=10/36, reported this issue during UAT feedback collection). This review step implemented defensive design principles that reduced prediction errors caused by data entry mistakes while supporting the deliberative decision-making style characteristic of experienced farmers (Table 6: 3-40+ years farming experience).
The prediction results interface (Figures 33b-d) implemented Requirement FR5 (Transparent Prediction Result Presentation) through a progressive disclosure design that balanced simplicity (Figure 33b: yield estimate only) with analytical depth (Figures 33c-d: unit conversions and feature importance). The simple results view emphasized the primary prediction (8,450 kg in the illustrated example) using large, bold typography and high contrast, ensuring readability even for users with visual impairments or in outdoor lighting conditions. The "View Details" option revealed additional context for farmers seeking deeper understanding, without overwhelming those satisfied with the basic estimate.
The detailed results view (Figure 33c) added practical unit conversions that aligned with how farmers conceptualize and communicate yields in the local context. The cavan conversion (yield ÷ 50 kg/cavan) reflected the traditional Philippine rice measurement unit still commonly used for historical comparisons and informal transactions. The sack conversion (yield ÷ 50 kg/sack) corresponded to the standard packaging unit for commercial sales and storage planning. These conversions required no additional model computation, where they were simple arithmetic transformations of the primary kilogram-based prediction, but substantially enhanced practical utility by providing farmers with familiar reference points.
(insert pics here)
Figure 34. Feature importance visualization implementing the transparency component of Requirement FR5. Horizontal bar chart displaying relative importance scores for all 27 input variables (X1-X27), ranked in descending order of contribution to yield prediction. Longer bars indicate features with stronger influence on the predicted yield for the specific farm input combination. The chart uses impurity-based importance values from the trained Random Forest model, providing farmers with interpretable insights into which agronomic factors (e.g., fertilizer applications, land area, pest pressures) most strongly affected their yield estimate.
The feature importance chart (Figure 34) addressed the interpretability component of Requirement FR5, translating the Random Forest model's internal importance scores into a visual format accessible to non-technical users. The chart displayed all 27 features (X1-X27) ranked by their relative contribution to reducing prediction uncertainty across the 200 decision trees in the ensemble. Features with longer bars indicated variables that appeared frequently in tree split decisions and contributed substantially to partitioning farms into more homogeneous yield groups.
This transparency mechanism helped farmers understand why the model produced a particular prediction for their specific input combination, addressing potential concerns about trusting "black box" algorithmic recommendations documented during requirements planning (Table 11, FR5 rationale). For example, if the chart showed high importance for Total Nitrogen - First Application (X9) and Land Area (X1) but low importance for weather challenges (X27), the farmer could infer that their predicted yield was primarily driven by basal fertilization and farm size rather than environmental factors, providing actionable insights for management optimization.
The visualization used horizontal bars rather than vertical bars to accommodate long feature names without text rotation, improving readability. The feature labels (X1-X27) corresponded to the variable definitions in Table 5 of the methodology, enabling cross-reference for readers seeking detailed feature descriptions. The chart rendered responsively across different screen sizes using Android's ConstraintLayout system, maintaining legibility on devices with varied display dimensions.
(insert pics here)
Figure 35. Prediction history management interface implementing Requirement FR6. (a) Recent predictions list showing a single saved entry with timestamp (date and time), predicted yield (8,450 kg), and quick action icons for viewing details or marking as favorite. (b) Multiple saved predictions demonstrating the scrollable history list with chronological organization (most recent first), supporting season-to-season comparison and longitudinal trend analysis. (c) Favorites tab displaying predictions that the farmer has bookmarked for quick access, facilitating rapid comparison of different input scenarios or retrieval of frequently referenced baseline configurations.
The history management interface (Figure 35) implemented Requirement FR6 through persistent Room database storage of all prediction sessions, supporting the longitudinal, experience-based decision-making mode documented in Table 7 (Theme I13: YouTube/SMS/technician advice used for periodic reinforcement) and Table 6 (decades of farming experience informing adaptive strategies). The Recent tab (Figure 35a-b) provided chronological access to all saved predictions, with timestamps enabling farmers to associate estimates with specific planting seasons or input procurement decisions. Each history entry displayed the predicted yield prominently, with tap actions revealing the complete input configuration and detailed results for that session.
The Favorites feature (Figure 35c) addressed the sensitivity analysis and scenario comparison use case identified during requirements planning. Farmers could bookmark particularly informative predictions (e.g., baseline typical-year configuration, best-case optimized inputs, worst-case minimal inputs) for quick retrieval without scrolling through the full chronological history. This capability supported "what-if" exploration of input adjustments, enabling farmers to compare how changes in fertilizer quantities, pest management, or variety selection affected predicted yields under otherwise constant conditions.
The database implementation used an indexed Room schema with entity classes for PredictionHistoryEntity (containing prediction metadata) and PredictionInputEntity (containing the complete 27-feature input vector). Queries were optimized through indexing on timestamp (for chronological Recent tab sorting) and favorite flag (for efficient Favorites tab filtering), ensuring responsive list rendering during user interactions. The local-only storage with Android OS-level sandbox protection (Requirement NFR4) ensured that this longitudinal farm data remained exclusively on the farmer's device, with no cloud synchronization or external data sharing that could raise privacy concerns.
System integration and deployment
The GabayPalay application successfully integrated all functional components (model inference engine, user interface, database layer) into a cohesive system validated against the complete set of derived requirements. The deployment package consisted of a signed APK file (12.4 MB) compatible with Android 8.0+ devices, accompanied by installation instructions in English for offline distribution via Bluetooth transfer and online distribution through social media messaging platforms (e.g., Facebook Messenger, Telegram) to accommodate both the limited internet connectivity and the mobile-first communication patterns documented in Table 12 (Connectivity constraint). The modest APK size (12.4 MB) enabled rapid transfer through Bluetooth on devices without internet access, while social media platform distribution leveraged farmers' existing communication channels for those with intermittent connectivity.
Integration testing verified the end-to-end data flow from user input through feature vector construction, model inference, result presentation, and database persistence. The automatic NPK calculation from fertilizer inputs (implementing FR2) was validated against the preprocessing logic used during model training, with unit tests confirming that the application produced identical X9-X17 values for the same fertilizer configurations processed during the training data pipeline. This consistency ensured that the m2cgen-converted model received feature vectors with the same distribution and scaling characteristics as the training data, maintaining prediction accuracy across the development-to-deployment boundary.
The model integration achieved the perfect numerical parity documented in Table 16 (all 17 test samples: absolute difference = 0.00 kg, relative error = 0.0000%), confirming that the Java implementation preserved the complete decision tree ensemble structure without rounding errors or implementation discrepancies. Farmers using the deployed application therefore receive predictions with the same accuracy characteristics (test set R²=0.765, RMSE=2,286 kg, MAE=1,731 kg) as the rigorously validated scikit-learn model, ensuring scientific integrity and reliability in production use.
The application was deployed to 36 farmers during the user acceptance testing phase through in-person installation sessions where the research team transferred the APK file via Bluetooth or guided farmers to download it through social media messaging platforms, then provided initial setup guidance. This deployment approach addressed the digital literacy gaps and installation uncertainty documented in Table 7 (Theme I12: 100% non-usage of agricultural apps) while providing immediate technical support for any device-specific compatibility issues. Post-deployment support was provided through a dedicated contact number (specified in the informed consent form, Appendix 1) for farmers encountering technical difficulties during independent use.
The construction and implementation phase successfully translated all derived requirements into a working mobile application validated through comprehensive functional testing and user acceptance evaluation. All six functional requirements (FR1-FR6) were implemented with supporting evidence documented in Table 17. Five non-functional requirements (NFR1-NFR5) were validated with measured or observed performance meeting target specifications or appropriately adapted based on technical constraints, as documented in Table 18. Specifically, bilingual accessibility (NFR2) was partially met with English-only implementation justified by timeline constraints and validated through SUS scores confirming acceptable usability; database encryption (NFR4) was deferred in favor of OS-level sandbox security that satisfied the core privacy requirement; and performance/stability validation (NFR3, NFR5) relied on informal observations and user acceptance testing rather than formal systematic measurement, providing practical validation of acceptable performance for the target deployment context.
The systematic mapping between requirements (derived in Section 1 from empirical farmer needs), implementation (documented in this section with architectural decisions and UI design), and validation (quantitative test results and user feedback) established complete traceability across the RAD methodology phases, ensuring that the final application directly addressed the documented challenges and preferences of the target farmer population in Hagonoy, Davao del Sur. The technical adaptations made during construction—retaining the Java model class for interoperability, implementing Room database for type-safe persistence, deferring encryption and bilingual support—were documented transparently with technical justifications, maintaining the integrity of the research process while acknowledging practical constraints inherent in thesis-scope software development.
USER ACCEPTANCE TESTING AND USABILITY EVALUATION
Following successful implementation and functional validation of all system requirements (Tables 17-18), user acceptance testing was conducted with rice farmers from Hagonoy, Davao del Sur to evaluate the usability, usefulness, and adoption potential of the GabayPalay application. This section presents the results of RAD Phase 4 (Cutover and Validation), documenting participant characteristics, quantitative usability assessment through the System Usability Scale (SUS), technology acceptance evaluation through the Technology Acceptance Model (TAM), qualitative user feedback, and task completion analysis. The user acceptance testing specifically validated Requirement NFR2 (Usability and Multilingual Accessibility) through empirical assessment of the application's effectiveness for farmers with varying technological backgrounds.
Participant Demographics and Characteristics
User acceptance testing was conducted with 36 rice farmers from Hagonoy, Davao del Sur, recruited through coordination with the Municipal Agriculture Office and barangay officials following the sampling procedures described in the methodology. Participants represented diverse demographics and farming backgrounds, providing robust insights into usability across the spectrum of technological familiarity expected among potential users. The UAT sample was drawn from the same agricultural context as the qualitative interview participants (n=11, Table 6) and quantitative survey respondents (n=54, Table 10), ensuring consistency in farming practices, environmental constraints, and technology access patterns that informed the GabayPalay requirements specification. Table 19 summarizes the demographic characteristics of the UAT participant sample.
Table 19. Demographic characteristics of user acceptance testing participants (n=36).

Characteristic	Category	Count	Percentage
Sex	Male	30	83.3%
	Female	6	16.7%
Age Range	20-29 years	9	25.0%
	30-39 years	9	25.0%
	40-49 years	8	22.2%
	50-59 years	10	27.8%
Educational Attainment	Elementary Graduate	12	33.3%
	High School Graduate	17	47.2%
	College Level/Graduate	7	19.4%
Daily Smartphone Usage	Less than 1 hour	10	27.8%
	1-3 hours	14	38.9%
	3-5 hours	7	19.4%
	More than 5 hours	5	13.9%
Prior Agricultural App Experience	Yes	5	13.9%
	No	31	86.1%
Farming Experience (years)	2-10 years	13	36.1%
	11-20 years	11	30.6%
	21-30 years	9	25.0%
	31-40 years	2	5.6%
	Not specified	1	2.8%
Farm Size (hectares)	0.30-1.00 ha	6	16.7%
	1.01-2.00 ha	13	36.1%
	2.01-3.00 ha	9	25.0%
	3.01-4.00 ha	5	13.9%
	>4.00 ha	1	2.8%
	Not specified	2	5.6%
The participant sample exhibited characteristics representative of the target farmer population in Hagonoy identified during the requirements planning phase. The predominant male representation (83.3%) reflected the gender composition observed in related agricultural studies and aligned with documented patterns of farm management responsibility in Philippine rice agriculture (David, 2023; Palis et al., 2006). The age distribution spanned early-career to experienced farmers (range: 23-58 years; median: 43 years), with balanced representation across four decade-based cohorts ensuring insights from multiple generational perspectives on technology adoption.
Educational attainment ranged from elementary graduates (33.3%) to college-level or college graduates (19.4%), with high school graduates forming the plurality (47.2%). This distribution corresponded closely to the educational profile observed during the quantitative survey and represented the literacy levels for which the English-only interface needed to provide adequate usability. The predominance of elementary and high school graduates (80.5% combined) validated the constraint analysis (Table 12, Technical Skill constraint) that anticipated limited experience with form-based data entry and potential confusion with agronomic terminology as barriers requiring simplified interaction patterns specified in NFR2.
Daily smartphone usage showed concentration in the 1-3 hour range (38.9%), with 27.8% reporting less than 1 hour and only 13.9% exceeding 5 hours. This pattern suggested moderate but not extensive digital device engagement, supporting the interface design emphasis on simplicity and visual guidance established in Requirement NFR2. The substantial proportion of minimal smartphone users (27.8% with less than 1 hour daily usage) directly validated the adoption constraint documented in Table 12, which identified digital literacy gaps across farmer age ranges and variable familiarity with smartphone interface conventions as anticipated barriers to adoption.
Critically, 86.1% of participants (n=31) reported no prior experience using agricultural mobile applications, directly validating the baseline condition documented in the qualitative phase (Table 7, Theme I12: 100% non-usage among interview participants, n=11) that informed the usability requirements specification. This finding empirically confirmed the adoption constraint analysis (Table 12) which identified zero baseline usage of farm-specific agricultural applications among all interview participants as a primary barrier to technology adoption. Only five participants (13.9%) had previous exposure to agricultural apps, specifically Rice Doctor (n=1), PlantNet (n=1), Rice Crop Manager (n=1), RiceAdvice (n=1), and Clarifruit/Freshness Detector (n=1). This predominance of first-time agricultural app users ensured that the UAT results reflected the application's performance for its primary target audience: farmers unfamiliar with digital agricultural decision support tools.
Farming experience ranged from 2 to 35 years (median: 18 years), encompassing the range observed in qualitative interviews (3-40+ years, Table 6) and aligning with the operational knowledge base that informed implicit decision rules for input timing and quantity adjustments documented in the requirements planning phase. The majority of participants (66.7%) represented established farmers with more than 10 years of experience, while 36.1% represented relatively recent entrants to rice farming (2-10 years), paralleling the experience distribution documented in the quantitative survey. One participant did not specify farming experience.
Farm size distribution showed concentration in small- to medium-scale operations, with 36.1% managing 1.01-2.00 hectares and 25.0% managing 2.01-3.00 hectares. This distribution was consistent with the landholding patterns documented in the quantitative survey (Table 10: median 1.00 ha, IQR 0.75-2.00 ha) and the qualitative interview sample (0.30-8.50 ha, Table 6), though the UAT sample included fewer large-scale operations (greater than 4.00 ha: 2.8%) compared to the survey population. Two participants did not specify farm size. The median farm size among UAT participants was approximately 2.0 hectares, characteristic of Philippine smallholder rice agriculture and representative of the farm-scale variability for which the GabayPalay application needed to provide accurate predictions.
System Usability Scale Assessment
The System Usability Scale (SUS), a standardized 10-item questionnaire developed by Brooke (1996), was administered to quantitatively assess the perceived usability of the GabayPalay application and validate Requirement NFR2 (Usability and Multilingual Accessibility). Each item was rated on a 5-point Likert scale ranging from 1 (Strongly Disagree) to 5 (Strongly Agree). SUS scores were calculated following the standard scoring procedure: for odd-numbered items (positive statements), the score contribution is the scale position minus 1; for even-numbered items (negative statements), the contribution is 5 minus the scale position. The sum of all item contributions is multiplied by 2.5 to yield a composite score from 0 to 100 for each participant.
Table 20 presents the summary statistics for SUS scores across all 36 participants, along with the mean scores for each individual SUS item to provide insight into specific usability dimensions.

Table 20. System Usability Scale (SUS) scores and item-level analysis from farmer participants (n=36).

Overall SUS Score	Value	Interpretation
Mean SUS Score	60.3	Below acceptable threshold (Brooke, 1996; Bangor et al., 2009)
Standard Deviation	19.5	High variability across users
Minimum Score	27.5	Lowest individual rating
Maximum Score	100.0	Highest individual rating (perfect score)
Median Score	58.8	Central tendency indicator
Scores ≥70 (Acceptable)	15 (41.7%)	Proportion meeting acceptability threshold
Scores ≥80 (Excellent)	6 (16.7%)	Proportion rating as excellent




Individual SUS Items	Mean Score	Interpretation
SUS1: I think I would like to use this system frequently	3.53	Moderate positive intention
SUS2: I found the system unnecessarily complex	2.81	Moderate complexity perception
SUS3: I thought the system was easy to use	3.75	Moderate to high ease of use perception
SUS4: I think I would need technical support to use this system	3.19	Moderate support dependency
SUS5: I found the various functions well integrated	3.58	Good integration perception
SUS6: I thought there was too much inconsistency	2.50	Low inconsistency perception
SUS7: I would imagine most people would learn to use this system quickly	3.58	Moderate learnability perception
SUS8: I found the system very cumbersome to use	2.50	Low awkwardness perception
SUS9: I felt very confident using the system	3.78	Moderate to high confidence
SUS10: I needed to learn a lot of things before I could get going	3.11	Moderate learning barrier

The mean SUS score of 60.3 (SD=19.5) fell below the threshold of 70 that Brooke (1996) established as indicating acceptable usability, indicating that Requirement NFR2's usability target was not fully met despite the implementation of simplified interaction patterns and visual guidance. According to the refined SUS interpretation framework proposed by Bangor et al. (2009), scores between 50 and 70 correspond to marginal to acceptable usability, while scores below 50 indicate poor usability and scores above 70 indicate good to excellent usability. The GabayPalay application's mean score of 60.3 falls within the lower end of the acceptable usability range, suggesting that while the application provided functional capability, significant usability barriers remained for a substantial portion of the target farmer population.
This below-threshold result directly validated the adoption constraints documented in the requirements planning phase (Table 12). The constraint analysis explicitly identified digital literacy gaps across farmer age ranges, zero baseline usage of farm-specific agricultural applications, and limited experience with form-based data entry as barriers anticipated to impact usability. The empirical SUS score of 60.3 confirmed that these constraints manifested as measurable usability challenges during actual usage, despite the design interventions implemented to address them through simplified UI, visual guidance, and staged input workflow.
The distribution of SUS scores revealed considerable polarization in usability perceptions. While 41.7% of participants (15 out of 36) rated the application at or above the acceptability threshold of 70, the majority (58.3%, 21 out of 36) scored below this threshold, indicating that most users encountered non-trivial usability difficulties. Only 16.7% of participants (6 out of 36) assigned scores of 80 or higher, reflecting excellent usability experiences among a small minority of users. One participant achieved a perfect SUS score of 100, demonstrating that the application could deliver exceptional usability experiences for technologically proficient users. These high scorers tended to be younger farmers (age less than 40 years) with college-level education and extensive daily smartphone usage (greater than 3 hours), confirming that technological familiarity and educational attainment strongly mediated usability perceptions, consistent with the technical skill constraint documented in Table 12.
The standard deviation of 19.5 points indicates high variability in usability perceptions across participants, substantially greater than typical SUS standard deviations (10-15 points) reported in general usability studies. This elevated variability reflected the wide spectrum of technological familiarity, educational backgrounds (ranging from 33.3% elementary to 19.4% college graduates), and prior experience with smartphone applications within the participant sample. The minimum score of 27.5, categorized as worst imaginable usability according to Bangor et al. (2009), was recorded for three participants, all elementary graduates with less than 1 hour daily smartphone usage and no prior agricultural app experience. These extreme low scores highlight the severity of usability challenges for users at the lower end of the digital literacy spectrum, validating the constraint analysis (Table 12) that identified this population segment as particularly vulnerable to adoption barriers.
Conversely, the maximum score of 100 and the presence of six users scoring at or above 80 (16.7%) demonstrated that for technologically capable users, the interface design successfully provided intuitive, efficient interactions. This bifurcation of usability experiences, with some users finding the application excellent while others found it nearly unusable, reflected the fundamental challenge identified in the constraint analysis: designing a single interface to accommodate users with extreme variation in technological capability (Table 12, Adoption constraint).
The item-level analysis provides granular insights into specific usability dimensions and their alignment with the functional requirements derived from farmer practices. Positive statements (odd-numbered items: SUS1, SUS3, SUS5, SUS7, SUS9) received moderate to moderately high mean scores (range: 3.53-3.78), indicating general but not universal agreement that the system was easy to use, well-integrated, learnable, confidence-inspiring, and desirable for frequent use. The highest positive item score was SUS9, "I felt very confident using the system" (M=3.78), suggesting that users who successfully completed the workflow gained self-efficacy despite initial challenges. However, this score was notably lower than the 4.0 or higher scores typically observed in applications with strong usability, indicating residual uncertainty even among successful users
The relatively lower score for SUS1, "I would like to use this system frequently" (M=3.53), revealed important insights about adoption intention. While users recognized the application's utility (validated by high TAM Perceived Usefulness scores discussed in the next subsection), their enthusiasm for frequent usage was tempered by the effort required to interact with the interface. This finding aligns with the temporal constraint documented in Table 12, which anticipated seasonal decision-making rhythm with concentrated usage during pre-planting planning rather than daily engagement, suggesting that the application correctly anticipated intermittent rather than continuous usage patterns.
Negative statements (even-numbered items: SUS2, SUS4, SUS6, SUS8, SUS10) received moderate mean scores (range: 2.50-3.19), with notably higher scores on SUS4 and SUS10 compared to other negative items. The elevated score for SUS4, "I think I would need technical support" (M=3.19), indicated that many farmers anticipated requiring assistance to use the application effectively, a concern that materialized in the qualitative feedback where 22.2% of participants reported needing help from someone else during testing. This finding directly validated the adoption constraint (Table 12) that identified limited digital literacy preventing independent tool usage as a barrier, and it highlighted a critical gap in the Getting Started guide's (Figure 29c) effectiveness for the least technologically experienced users.
Similarly, the moderate score for SUS10, "I needed to learn a lot before I could get going" (M=3.11), indicated mixed perceptions about the learning curve. While the staged input workflow (FR2) and visual guidance were designed to reduce the learning barrier, approximately half of participants still perceived a non-trivial learning investment. This perception aligned with the documented task completion times (mean=49.8 min, discussed later) which revealed that first-time users required substantial time to complete the prediction workflow, particularly those with elementary education (mean=71.2 min) and minimal smartphone usage (mean=73.5 min for less than 1 hour per day users).
The relatively lower scores for SUS6, "I thought there was too much inconsistency" (M=2.50), and SUS8, "I found the system very cumbersome to use" (M=2.50), suggested that the interface design successfully maintained consistency across screens and avoided gratuitous complexity. These scores validated the architectural decision (Phase 3) to implement a layered modular design (Figure 21) with standardized UI components and predictable navigation patterns. However, the scores remained above the ideal target of 2.0 or lower for negative items, indicating that some users still perceived minor inconsistencies or awkwardness during interactions.
The moderate score for SUS2, "I found the system unnecessarily complex" (M=2.81), occupied a middle ground, suggesting that while the application avoided extreme complexity, many users still found aspects of the interface more complicated than necessary. This perception likely stemmed from the technical agricultural terminology (NPK display, fertilizer formulations) and multi-stage data entry requirements (FR2: three-phase fertilization pattern) that were essential for model accuracy but challenging for users with limited formal education. The constraint analysis (Table 12, Measurement Precision constraint) explicitly acknowledged this tension between farmer recall and estimation for input quantities using variable units of measurement and the need for standardized inputs, creating challenges that the interface could mitigate but not entirely eliminate.
To contextualize the GabayPalay SUS score within the broader landscape of agricultural mobile applications and assess achievement of NFR2, it is instructive to compare the result against established benchmarks and related agricultural app studies. Bangor et al. (2009) established that SUS scores above 70 correspond to the 50th percentile or higher in their analysis of 2,324 SUS surveys across diverse products. The GabayPalay score of 60.3 thus performs below the median of general commercial applications, indicating that usability challenges exceeded those typically encountered in mainstream consumer software.
More critically, the score fell below the explicit target established in Requirement NFR2 (Table 11), which specified that the application user interface must exhibit simplified interaction patterns, clear visual hierarchy, and intuitive navigation achieving a System Usability Scale target of 70 or higher. This target was specifically calibrated to the constraint that 86.1% of the target population had zero prior agricultural app usage experience. The failure to achieve this target indicated that the simplified interaction patterns implemented, including the Getting Started guide (Figure 29c), staged input workflow (Figures 30-32), and visual affordances, were insufficient to fully compensate for the severe digital literacy gaps documented in the qualitative phase (Table 7, Theme I12: 100% non-usage).
However, it is essential to contextualize this finding within the acknowledged limitations documented during the Construction phase (Phase 3). The NFR2 validation section (Table 18) explicitly noted that English-only labels were implemented while Bisaya localization was deferred due to timeline constraints. The requirements specification (Table 11, NFR2) originally included bilingual (English/Bisaya) support with culturally appropriate terminology as a usability requirement, recognizing that alignment with local linguistic preferences would improve comprehension and reduce cognitive load. The decision to defer Bisaya localization, while justified by development timeline constraints, likely contributed to the below-threshold SUS score, particularly for elementary-educated farmers who may have had limited English proficiency despite demonstrating functional literacy during the survey data collection (Appendix 3).
Compared to the agricultural machine learning application developed by David (2023), who did not report formal usability assessment despite targeting a similar Philippine rice farming context, the GabayPalay project's systematic SUS evaluation provides quantitative validation of usability that strengthens claims of empirical rigor, even when the results reveal challenges. The transparent reporting of a below-threshold score, supported by comprehensive item-level analysis and demographic correlations, represents a more honest and scientifically valuable contribution than omitting usability assessment or reporting only positive outcomes.
The achievement of marginal usability (SUS=60.3) for a population with 86.1% first-time agricultural app users, while falling short of the target threshold, nonetheless demonstrated that the simplified interface design (NFR2), visual guidance, and alignment with farmer mental models (informed by qualitative themes in Tables 6-7) enabled functional task completion for the majority of users. The 41.7% of users who rated the application as acceptable (SUS greater than or equal to 70) and the 16.7% who rated it as excellent (SUS greater than or equal to 80) confirmed that the design successfully accommodated users at the higher end of the digital literacy spectrum. The challenge lay in extending this usability to the substantial population segment (58.3%) with minimal technological experience and elementary education, a challenge that the constraint analysis (Table 12) anticipated but underestimated in severity.
Technology Acceptance Model Evaluation
The Technology Acceptance Model (TAM), developed by Davis (1989), was employed to assess user acceptance of the GabayPalay application through two primary constructs: Perceived Usefulness (PU) and Perceived Ease of Use (PEOU). Each construct was measured using five items rated on a 5-point Likert scale (1 = Strongly Disagree, 5 = Strongly Agree), following the validated TAM instrument structure used in agricultural technology adoption studies (Tey & Brindal, 2012). Additionally, the Net Promoter Score (NPS) was collected as an indicator of recommendation likelihood and overall satisfaction. Table 21 summarizes the mean scores and standard deviations for each TAM construct and their constituent items.
Table 21. Technology Acceptance Model (TAM) assessment results (n=36 farmers).
TAM Construct	Mean Score	Std. Dev.	Interpretation
Perceived Usefulness (PU)	3.97	0.65	High perceived value
PU1: Helps make better farming decisions	3.92	0.73	Farmers see decision support benefit
PU2: Increases productivity	3.81	0.79	Strong productivity expectations
PU3: Saves time in planning	4.08	0.69	Efficiency gains strongly recognized
PU4: Improves yield prediction accuracy	4.17	0.70	High confidence in model accuracy
PU5: Overall usefulness	3.86	0.72	Strong utility perception
Perceived Ease of Use (PEOU)	3.37	0.99	Moderate ease of use
PEOU1: Easy to learn	3.14	0.99	Moderate learnability perception
PEOU2: Clear and understandable	3.50	1.08	Some clarity challenges noted
PEOU3: Easy to navigate	3.47	1.03	Navigation mostly intuitive
PEOU4: Doesn't require much effort	3.25	1.11	Moderate to high cognitive load
PEOU5: Overall ease of use	3.50	1.00	Moderate ease perception
Net Promoter Score (NPS)	6.83	1.95	Good recommendation likelihood (0-10 scale)
The TAM assessment revealed a striking pattern: high Perceived Usefulness substantially exceeded moderate Perceived Ease of Use. This divergence provides critical insights into the adoption potential of the GabayPalay application, revealing that while farmers recognized substantial value in the yield prediction capabilities, usability barriers validated by the below-threshold SUS score constrained their enthusiasm and willingness to recommend the application to others.
Perceived Usefulness achieved a high mean score (M=3.97, SD=0.65), indicating that farmers recognized substantial value in the application's yield prediction capabilities (FR1) and their potential to enhance farming decisions. All five PU items exceeded 3.80, with "improves yield prediction accuracy" (M=4.17) and "saves time in planning" (M=4.08) receiving particularly strong endorsement. These high scores validated Requirement FR5 (Transparent Prediction Result Presentation), suggesting that farmers perceived the prediction outputs and feature importance visualizations as credible and actionable, addressing the trust concerns regarding app accuracy and relevance documented during qualitative interviews (Table 11, FR5 evidence column).
The highest PU item score, "improves yield prediction accuracy" (M=4.17), is particularly significant given the model's empirical performance (test set R²=0.765, RMSE=2,286 kg documented in Phase 2). Farmers' confidence in prediction accuracy suggests that the transparent presentation of results, including the feature importance chart (Figure 34) showing which agronomic factors most strongly influenced their specific prediction, successfully built trust in the model's credibility despite its imperfect accuracy. During UAT sessions, several farmers spontaneously verbalized this perceived accuracy: "Maayo ni kay makita nako unsa ang importante para sa ani" (This is good because I can see what's important for the harvest), validating the FR5 goal of transparent result presentation. This finding aligns with literature on explainable artificial intelligence, where interpretability can enhance user trust even when absolute accuracy is moderate (Ajayi et al., 2024).
The second-highest PU score, "saves time in planning" (M=4.08), reflected farmers' appreciation for the efficiency gains enabled by immediate predictions and scenario comparison through the History feature (FR6). This finding is noteworthy because it emerged despite the substantial initial time investment required to complete the first prediction (mean=49.8 min, discussed later). Farmers evidently recognized that while the initial data entry was time-consuming, subsequent predictions and season-to-season comparisons would streamline decision-making, aligning with the temporal constraint documented in Table 12 which anticipated seasonal decision-making rhythm with concentrated usage during pre-planting planning rather than daily engagement.
The relatively low standard deviation (0.65) across all PU items indicates consistent recognition of value across participants with diverse backgrounds, suggesting that the application's utility was apparent even to farmers with limited technological experience. During UAT sessions, farmers explicitly connected this value to their fertilizer management challenges: "Makatabang gyud ni sa planning, labi na sa fertilizer" (This will really help with planning, especially fertilizer), directly reflecting the documented need for decision support in fertilizer management, where farmers reported experience-based adjustments without formal optimization (Table 8: wide variation in total season fertilizer ranging from approximately 4 to 12 sacks per hectare documented in qualitative interviews).
The strong PU scores across all items validated the requirements planning process (Phase 1) which systematically derived functional requirements (FR1-FR6) from empirical observations of farmer practices and needs. The finding that farmers recognized value in yield prediction (PU4=4.17), time savings (PU3=4.08), and decision support (PU1=3.92) confirmed that the application addressed genuine agricultural challenges rather than imposing technological solutions without farmer-validated need.
However, the slightly lower score for PU5, "overall usefulness" (M=3.86), compared to specific functional items suggested that while farmers appreciated individual features, some uncertainty remained about the application's comprehensive value proposition. This may reflect the single-use nature of the testing session; sustained usage over multiple cropping seasons would likely strengthen perceptions of overall utility as farmers experienced tangible benefits from prediction-informed decisions and seasonal trend analysis enabled by historical record management (FR6).
Perceived Ease of Use scores (M=3.37, SD=0.99) were moderate but notably lower than Perceived Usefulness (difference=0.60), a pattern consistent with TAM literature showing that PEOU often scores lower than PU for novel technologies requiring learning investment (Venkatesh & Davis, 2000). The PEOU scores aligned closely with the below-threshold SUS results (mean 60.3), providing convergent validity that usability challenges existed across multiple measurement approaches. The convergence between moderate PEOU (3.37 out of 5.0 equals 67.4% of maximum) and below-threshold SUS (60.3 out of 100 equals 60.3% of maximum) strengthened the conclusion that while most farmers found the application marginally usable, significant ease-of-use barriers remained, particularly for users with limited smartphone experience.
The items "easy to learn" (M=3.14) and "doesn't require much effort" (M=3.25) received the lowest PEOU scores, with high standard deviations (0.99-1.11) indicating substantial disagreement among participants. This variability suggested that technological familiarity strongly influenced ease-of-use perceptions: technologically proficient farmers (college-educated with greater than 3 hours daily smartphone usage) found the application straightforward (SUS mean=81.5 for greater than 5 hours per day users), while those with minimal smartphone experience (elementary-educated with less than 1 hour daily usage) encountered meaningful difficulties (SUS mean=37.0 for less than 1 hour per day users). The moderate scores on these items aligned with qualitative feedback indicating that data entry, especially for the Nutrient Management module implementing the stage-based fertilization pattern (FR2, Table 8), required deliberative effort to recall and accurately report fertilizer applications across the three timing windows.
The item "clear and understandable" (M=3.50) received a moderate score, consistent with qualitative feedback identifying specific confusion points including NPK display interpretation (27.8% of participants, discussed in User Feedback subsection), fertilizer selection labels (25.0%), and unit conversion between kilograms and sacks (22.2%). These clarity challenges reflected the measurement precision constraints documented in Table 12, where farmers' variable units of measurement (sacks versus kilograms; sachets versus liters) and approximations in quantity recall created tension with the application's requirement for standardized inputs. While not severe enough to prevent task completion for most users, these challenges suggested opportunities for refinement through clearer labeling, contextual tooltips, and potentially the deferred Bisaya translation (NFR2, Table 18) that would align technical terminology with local linguistic preferences and mental models established through intergenerational knowledge transfer (Table 7, Theme I13).
The relatively higher scores for "clear and understandable" (M=3.50), "easy to navigate" (M=3.47), and "overall ease of use" (M=3.50) compared to the learning and effort items suggested that the core interface design successfully provided logical information architecture and predictable interaction patterns. These scores validated the effectiveness of the staged input workflow (FR2) organized according to the three-phase fertilization pattern documented in 100% of interview participants (Table 7, Theme I9) and the tabbed interface design that provided clear separation between pre-planting, nutrient management, pest management, and weather data collection stages (Figures 30-32).
The higher standard deviations across all PEOU items (0.99-1.11) compared to PU items (0.65-0.79) indicated greater variability in ease-of-use perceptions, likely correlated with technological familiarity, educational attainment (ranging from 33.3% elementary to 19.4% college), and working memory capacity. This finding reinforced the importance of designing for the least technologically proficient user segment while ensuring that the interface didn't impede efficiency for more experienced users, a design tension acknowledged in the adoption constraint analysis (Table 12) but only partially resolved in the current implementation.
The Net Promoter Score (NPS), measured on a 0-10 scale, achieved a mean of 6.83 (SD=1.95), indicating moderate to good recommendation likelihood. Traditional NPS interpretation categorizes respondents as Promoters (9-10), Passives (7-8), and Detractors (0-6), enabling calculation of the Net Promoter Score as percentage of Promoters minus percentage of Detractors. The distribution revealed concerning insights. Promoters (9-10) comprised 9 participants (25.0%) expressing strong enthusiasm and high recommendation likelihood. Passives (7-8) comprised 11 participants (30.6%) showing positive but reserved attitudes. Detractors (0-6) comprised 16 participants (44.4%) expressing lower satisfaction or recommendation likelihood.
The calculated Net Promoter Score was 25.0% minus 44.4% equals negative 19.4%, a negative score indicating that Detractors outnumbered Promoters. In commercial contexts, negative NPS scores signal serious adoption challenges, as users are more likely to discourage others from using the product than to recommend it (Reichheld, 2003). This finding aligned with and extended the below-threshold SUS score, confirming that usability barriers not only impeded individual user experiences but also undermined word-of-mouth adoption potential.
The relatively high standard deviation (1.95) indicates considerable variation in overall satisfaction levels, consistent with the variability observed in SUS (SD=19.5) and PEOU (SD=0.99-1.11) scores. The presence of a Promoter segment (25.0%) suggested potential for organic diffusion through farmer networks among early adopters and technologically proficient farmers, addressing the adoption constraint that awareness does not automatically translate to sustained use (Table 12). However, the substantial Detractor segment (44.4%) indicated that significant barriers to adoption remained for nearly half the user population, likely those with the lowest technological familiarity and digital literacy (corresponding to the 27.8% with less than 1 hour daily smartphone usage and 33.3% with elementary education).
Several participants who provided high NPS scores offered enthusiastic qualitative feedback that validated the strong PU scores. One 25-year-old male high school graduate farmer (NPS=9) stated: "Solid ang app bai! Modern na jud ni siya. Dali lang gamiton ug daghan tabang sa pag-uma" (The app is solid! It's really modern. Easy to use and very helpful for farming). A 26-year-old male high school graduate (NPS=9) expressed: "Grabe ka helpful ani! Naay calculator, prediction, recommendation, kompleto na!" (This is extremely helpful! It has calculator, prediction, recommendation, it's complete!). These testimonials came predominantly from younger, more educated participants (all aged less than 30 years with college education or extensive smartphone usage), confirming that the application resonated strongly with technologically comfortable users but failed to achieve comparable acceptance among the broader farmer population.
Conversely, participants with low NPS scores often cited specific usability barriers in their qualitative feedback, including NPK confusion, need for external help, and difficulty with fertilizer selection and unit conversion. The correlation between low NPS, low SUS, elementary education, and minimal smartphone usage validated the constraint analysis (Table 12) that identified this population segment as particularly vulnerable to adoption barriers.
The TAM framework posits that Perceived Usefulness and Perceived Ease of Use jointly influence behavioral intention and technology adoption (Davis, 1989). The GabayPalay results show that PU (3.97) substantially exceeds PEOU (3.37), with a gap of 0.60 points (15% difference relative to the 5-point scale maximum). This pattern is consistent with TAM literature indicating that usefulness is often a stronger predictor of adoption intention than ease of use, particularly for utilitarian systems where functional value justifies learning effort (Venkatesh & Davis, 2000).
The relatively high PU scores despite substantially lower PEOU scores suggested that farmers were willing to invest effort to use the application because they perceived substantial value in its yield prediction capabilities, addressing the documented need for formalized decision support to replace purely experience-based adjustments (Table 6: decision rules implicitly formed by intuitive processing). This pattern validated the requirements planning decision to prioritize functional completeness (FR1-FR6: offline capability, stage-based management, variety classification, pest recording, transparent results, historical records) over absolute ease of use, recognizing that farmers would tolerate moderate complexity if the tool delivered credible, actionable insights grounded in local Hagonoy conditions.
However, the magnitude of the PU-PEOU gap (0.60 points) and the negative NPS score (negative 19.4%) suggested that moderate ease of use was insufficient to support widespread adoption. TAM research demonstrates that improving PEOU not only directly increases adoption but also strengthens PU perceptions as users more readily engage with and comprehend system features (Venkatesh & Davis, 2000). The current implementation, while delivering high perceived utility, placed too much cognitive burden on users with limited digital literacy, resulting in recommendation reluctance even among users who recognized value.
The empirical finding that 44.4% of users were Detractors despite 97% recognizing usefulness (PU greater than or equal to 3.5 on individual items: 35 out of 36 participants) highlighted a critical adoption barrier: perceived usefulness is necessary but insufficient for technology acceptance when ease of use falls below a critical threshold. For the GabayPalay application, that threshold appeared to correspond to approximately SUS equals 70 and PEOU equals 3.5, above which users transitioned from Detractors or Passives to Promoters.
Addressing the specific usability challenges identified in qualitative feedback could narrow the PU-PEOU gap and elevate PEOU above the critical threshold, potentially converting Detractors and Passives into Promoters. The constraint analysis (Table 12) identified several addressable barriers: Bisaya localization (deferred in current implementation, Table 18), contextual help for technical terminology (NPK display), and proactive input validation. Implementing these refinements in future iterations could preserve the high PU scores while substantially improving PEOU, unlocking the adoption potential indicated by farmers' recognition of value.
User Feedback and Observed Challenges
Qualitative feedback collected during user testing sessions provided insights into specific usability challenges and areas for potential improvement. Following each participant's completion of the prediction workflow, a semi-structured debriefing was conducted asking: "What difficulties did you encounter while using the application?" Responses were recorded verbatim (in English or Bisaya) and subsequently categorized by theme. Participants could report multiple challenges, so percentages exceed 100%. Table 22 summarizes the frequency of commonly reported challenges.
Table 22. Frequency of user-reported challenges during application testing (n=36).
Challenge Category	Count	Percentage	Example User Feedback (Verbatim)
Confused by NPK display	10	27.8%	"Confused by NPK display"; "Wala kasabot sa NPK numbers" (Didn't understand NPK numbers)
Didn't understand fertilizer selection	9	25.0%	"Didn't understand fertilizer selection"; "Wala kasabot sa pagpili ug abono" (Didn't understand fertilizer selection)
Had to go back and correct mistakes	8	22.2%	"Had to go back and correct mistakes"; "Nag-balik ko kay sayop akong gi-input" (I went back because my input was wrong)
Confused by unit selection (kg vs sacks)	8	22.2%	"Confused by unit selection kg vs sacks"; "Dili ko sure kung kg o sako" (I'm not sure if kg or sack)
Needed help from someone else	8	22.2%	"Needed help from someone else"; "Nagpatulong ko sa uban" (I asked for help from others)
Had trouble with pest selection	8	22.2%	"Had trouble with pest selection"; "Lisud pilion ang pests" (Hard to select pests)
Confused by land preparation options	7	19.4%	"Confused by land preparation options"; "Daghan kaayo ang choices sa land prep" (Too many choices for land prep)
None - everything smooth	6	16.7%	"Wala sa mga nahisgutan - hapsay ug dali ra ang tanan" (None of the mentioned issues - everything was smooth and easy)
Didn't know how to add fertilizer applications	6	16.7%	"Didn't know how to add more fertilizer applications"; "Dili ko kabalo unsaon pagdugang" (Don't know how to add more)
Didn't understand the results	4	11.1%	"Didn't understand the results"; "Wala kasabot sa mga resulta" (Didn't understand the results)
Couldn't find where to start prediction	4	11.1%	"Couldn't find where to start prediction"; "Wala makit-i kung asa magsugod" (Couldn't find where to start)
Couldn't find the Predict button	2	5.6%	"Couldn't find the Predict button"; "Wala makit-i ang 'Predict' button" (Couldn't find the 'Predict' button)
Had difficulty installing the app	2	5.6%	"Had difficulty installing the app"; "Lisud i-install" (Hard to install)

The most frequently reported challenge was confusion regarding the NPK (Nitrogen-Phosphorus-Potassium) display (27.8% of participants, n=10), indicating that the nutrient composition presentation required further clarification or contextual help. During UAT observations, several farmers paused at the nutrient management screen (Figure 31, implementing FR2: Stage-Based Agricultural Input Management) and asked clarifying questions such as "Unsa man ni nga numbers?" (What are these numbers?) and "Kini ba ang nitrogen?" (Is this the nitrogen?). While the application correctly computed NPK values from fertilizer inputs (validated through unit tests, Table 17), the display format did not align with farmers' mental models or local terminology for nutrient management.
This feedback suggested that while farmers could successfully complete the fertilizer input task by selecting familiar brand names (e.g., "Complete 14-14-14," "Urea 46-0-0," matching products reported in Table 8), the underlying NPK composition display intended to provide transparency (FR5) instead introduced confusion for users unfamiliar with explicit nutrient ratio notation. This finding reflected the technical skill constraint documented in Table 12, where potential confusion with agronomic terminology was anticipated as a design challenge. The constraint analysis proposed technical agricultural vocabulary minimized with plain-language explanations provided as a response, but the current implementation's NPK display evidently required additional contextualization.
Future iterations could address this through contextual tooltips explaining "N equals Nitrogen for leaf growth, P equals Phosphorus for roots, K equals Potassium for stems and disease resistance"; simplified visual indicators (e.g., color-coded bars for N, P, K levels relative to typical application rates from Table 8); optional display allowing users to hide technical details if desired, presenting only the total fertilizer quantity in familiar units (bags/sacks); or Bisaya translations of nutrient names that align with local agricultural extension terminology.
The second most common challenge, difficulty understanding fertilizer selection (25.0%, n=9), suggested that the five standardized fertilizer formulations offered (Table 8) did not fully capture the diversity of brand names and local product variations farmers encountered. Several farmers expressed uncertainty about which fertilizer type matched their product, with comments like "Naa ba diri ang Urea Gold?" (Is Urea Gold here?) and "Pareha ra ba ni sa akong gi-gamit?" (Is this the same as what I used?). The application offered five common formulations identified during requirements planning, but local brand variations sometimes caused confusion. This challenge reflected the measurement precision constraint (Table 12) where variable units of measurement (sacks versus kilograms; sachets versus liters) and approximations in quantity recall created tension with the application's need for standardized inputs.
Providing an "Other" fertilizer option with manual NPK ratio entry, or a searchable database of local brand names mapped to standard formulations, could accommodate this diversity. However, such features would introduce additional interface complexity, potentially exacerbating usability challenges for the least technologically proficient users, illustrating the fundamental tradeoff between flexibility and simplicity that the constraint analysis (Table 12, Technical Skill constraint) identified but did not fully resolve.
The issue of participants needing to return to previous screens to correct input mistakes (22.2%, n=8) suggested opportunities to enhance input validation feedback and provide clearer guidance during initial data entry to reduce error rates. The input review screen (Figure 33a) was specifically designed to address this need by allowing farmers to verify all entries before prediction execution, and most participants who reported going back successfully used the "Edit" button to correct errors. However, the frequency of corrections suggested that proactive validation during initial entry (e.g., immediate feedback if a value seems unusually high or low based on typical ranges from the quantitative survey, Table 10 and Appendix Tables 1-4) could prevent errors earlier in the workflow, reducing user frustration and completion time.
Equally common was confusion about unit selection between kilograms and sacks (22.2%, n=8), which stemmed from farmers' variable practices: some consistently thought in kilograms (following seed packaging standards, where FR3 specifies 15-40 kg per hectare validation ranges derived from the survey), while others habitually conceptualized quantities in sacks (following fertilizer purchasing patterns, where Table 8 reports approximately 4 sacks per hectare rainy or 3-4 bags complete). The application's unit dropdown (Figure 31d-e) provided both options and automatically converted between them, but the need to explicitly select a unit introduced a decision point that some farmers found confusing. Providing dual display (e.g., "25 kg (one-half sack)") in both input fields and result presentations could accommodate both mental models simultaneously, reducing cognitive translation burden.
The high frequency of participants needing help from someone else (22.2%, n=8) represented a significant finding that directly validated the digital literacy concerns documented in the qualitative phase (Table 7, Themes I12-I13). This reliance on external assistance occurred despite the presence of the Getting Started guide (Figure 29c, designed to address NFR2: simplified interaction patterns for low digital literacy) and suggested that certain interface elements or workflows exceeded the independent problem-solving capacity of less technologically experienced users. The need for help correlated strongly with lower educational attainment (elementary: 60% needed help; high school: 26% needed help; college: 0% needed help) and lower smartphone usage (less than 1 hour: 56% needed help; 1-3 hours: 29% needed help; greater than 3 hours: 10% needed help), confirming that digital literacy strongly mediated usability, consistent with the adoption constraint analysis (Table 12) that acknowledged limited digital literacy preventing independent tool usage.
This finding had critical implications for deployment strategy. The constraint analysis (Table 12, Adoption constraint) proposed community-based training programs, peer mentor support networks, and simplified printed quick-reference guides as responses to digital literacy barriers. The empirical evidence from UAT validated this proposal: 22.2% of users required help even during guided testing sessions with researcher presence. In real-world deployment without immediate support, this percentage would likely increase substantially, necessitating formal training programs and peer support networks rather than relying on self-directed learning from the Getting Started guide alone.
Difficulty with pest selection (22.2%, n=8) and confusion about land preparation options (19.4%, n=7) suggested that multi-option interfaces presented cognitive load issues for some users. The pest selection interface (Figure 32a) offered five binary checkboxes corresponding to the key pests identified through thematic analysis (Table 7: stem borer Theme I5, rats Theme I6, golden apple snail via molluscicide theme I3). While this design aligned with the documented pest management practices, some farmers found the checklist format unfamiliar or were uncertain whether specific pest observations during the season warranted checking the box. Similarly, land preparation options (manual, tractor, rotavator) could be selected in combination, reflecting the reality that farmers sometimes used multiple methods sequentially (Table 6), but this flexibility introduced uncertainty about which options to select.
Simplifying these interfaces through progressive disclosure (showing advanced options only when needed), providing visual examples for each pest type and land preparation method, or offering preset templates based on common practice patterns documented in Tables 6 and 8 could reduce cognitive burden. However, such simplifications risked reducing the input specificity that contributed to model accuracy, again illustrating the flexibility-simplicity tradeoff.
Difficulty adding multiple fertilizer applications (16.7%, n=6) indicated that the dynamic form generation approach (Figure 31a-c), where farmers first selected the number of application splits (1, 2, or 3) and the interface then generated the appropriate number of input sections, was not immediately intuitive to all users. Some farmers expected to add applications sequentially or did not notice the split selection dropdown. This finding suggested that the staged input workflow (FR2), while logically organized according to the three-phase fertilization pattern (Table 7, Theme I9: 100% reported 2-3 stages), required more explicit guidance or a different interaction model (e.g., "Add Application" button with dynamically appearing forms) to match farmers' expectations.
Navigation challenges, including difficulty finding where to start prediction (11.1%, n=4) and locating the Predict button (5.6%, n=2), indicated that despite the tabbed interface design and prominent "Predict Palay Yield" button on the home screen (Figure 29b), some users struggled with the application's information architecture. These users tended to have minimal prior smartphone app experience (matching the 86.1% with no prior agricultural app experience, Table 7, Theme I12) and may have been unfamiliar with standard mobile UI patterns (tabs, floating action buttons, bottom navigation). Enhanced visual hierarchy, animated onboarding tutorials (supplementing the static Getting Started guide), or simplified "Quick Predict" shortcuts could improve discoverability for first-time users.
Results interpretation difficulties (11.1%, n=4) suggested that while FR5 specified transparent prediction result presentation with confidence indicators and feature importance visualization (Figures 33-34), some farmers still struggled to understand the displayed information. This challenge may have reflected the tension between technical accuracy and accessible communication for users with elementary education (33.3% of sample) and limited exposure to data visualization conventions. Simplified result summaries with plain-language explanations of feature importance rankings, or comparison to local yield benchmarks (e.g., "Your predicted yield is above/below the average for Hagonoy" based on RiceLytics data, Figure 3), could improve comprehension.
Installation difficulties (5.6%, n=2) were relatively rare but noteworthy, as installation represents the critical first barrier to adoption. These challenges typically involved unfamiliarity with APK sideloading procedures (required for apps distributed outside Google Play Store, as was the case for the UAT pilot deployment) or Android security settings that block installation from unknown sources. This finding validated the connectivity constraint (Table 12) that recognized intermittent mobile data access and infrastructure variability across the study area as barriers to cloud-based app distribution. Future deployment through official app stores (Google Play Store) would eliminate this barrier entirely and align with typical user expectations for app acquisition.
Notably, 16.7% of participants (n=6) reported experiencing no difficulties whatsoever, describing the workflow as smooth and straightforward with feedback such as "Wala sa mga nahisgutan, hapsay ug dali ra ang tanan" (None of the mentioned issues, everything was smooth and easy). These users had higher educational attainment (college level or graduate: 4 out of 6) and more extensive daily smartphone usage (greater than 3 hours per day: 5 out of 6), confirming that technological familiarity significantly influenced ease of adoption. The existence of this group demonstrated that the interface design successfully accommodated users at the higher end of the digital literacy spectrum without introducing unnecessary complexity, supporting the design goal of progressive disclosure where advanced features were available but not mandatory.
Despite the challenges identified, participants also provided positive feedback indicating appreciation for the application's functionality and anticipated utility. One 36-year-old male high school graduate farmer (NPS=7) commented: "Maayo ang app. Makatabang sa computation. Pero unsay meaning sa NPK numbers?" (The app is good. Helpful for calculations. But what's the meaning of the NPK numbers?), reflecting both recognition of value and the specific NPK confusion challenge. A 31-year-old male high school graduate (NPS=8) stated: "Goods ni bai! Gamay ra issue sa units pero dali ra i-figure out. Helpful kaayo ang recommendations" (This is good! Small issue with units but easy to figure out. Very helpful recommendations), validating the utility perception while acknowledging the unit confusion challenge.
Several farmers compared GabayPalay favorably to existing agricultural apps they had used. A 28-year-old female high school graduate with prior Rice Doctor experience (NPS=8) noted: "Mas nindot pa ni kaysa Rice Doctor nga gigamit nako before" (This is even better than Rice Doctor that I used before), while a 32-year-old male high school graduate with Rice Crop Manager experience (NPS=7) commented: "Maayo ang app. Similar sa Rice Crop Manager pero naay yield prediction" (The app is good. Similar to Rice Crop Manager but has yield prediction). These comparisons suggested that the 13.9% with prior agricultural app experience could contextualize GabayPalay's features and found the yield prediction capability (FR1) particularly differentiating from available alternatives documented in Table 2.
The feedback requesting additional features was particularly instructive. Farmers spontaneously suggested weather integration, addressing the data availability constraint in Table 12 that excluded real-time weather API integration due to limited local measurement infrastructure. Others requested community forums, supporting the collaborative learning patterns documented in Table 7 (Theme I13: reliance on YouTube/SMS/technician advice). These forward-looking requests demonstrated that users envisioned the application as part of their long-term farming toolkit despite current usability challenges, indicating genuine engagement and investment in the application's success rather than merely polite responses.
Task Completion Time Analysis
User testing sessions tracked the time required for participants to complete the full prediction workflow from application launch to viewing results. Task completion times were recorded by noting the start time (when the participant opened the application) and end time (when the prediction results screen appeared, completing the FR1 offline yield prediction workflow), with breaks for clarification questions excluded from the measured time. Table 23 summarizes the task completion time distribution.

Table 23. Task completion time analysis for full prediction workflow (n=36 farmers).

Statistic	Value	Interpretation
Mean	49.8 minutes	Average time to complete workflow
Standard Deviation	20.4 minutes	Substantial variability across participants
Median	45.0 minutes	Central tendency less affected by outliers
Minimum	5.0 minutes	Fastest completion (experienced users)
Maximum	90.0 minutes	Slowest completion (least experienced user)
IQR (25th-75th percentile)	38.8 - 65.0 minutes	Middle 50% of completion times
Task completion times ranged from 5 to 90 minutes (mean=49.8 min, median=45.0 min, SD=20.4 min), with substantial variation reflecting differences in technological familiarity, reading speed, deliberation time for entering accurate farm data, and the need to recall specific input quantities across multiple stages (FR2: stage-based fertilization from Table 8). The 18-fold difference between fastest and slowest completion times highlighted the diverse capability spectrum within the target farmer population and validated the considerable SUS variability (SD=19.5) and PEOU variability (SD=0.99-1.11) observed in quantitative usability assessments.
The fastest completion times (5 minutes, n=2 participants) were achieved by participants with extensive smartphone usage (greater than 3 hours per day), college education, and in one case prior agricultural app experience, representing the Promoter segment (NPS 9-10) that expressed strong enthusiasm. These users navigated the interface confidently, rarely paused for clarification, and completed data entry efficiently, demonstrating that the interface could support rapid task execution for technologically proficient users. The achievement of 5-minute completion times suggested scalability for users who would perform predictions frequently across multiple cropping seasons (addressing the temporal constraint in Table 12: seasonal decision-making rhythm with concentrated usage during pre-planting planning), as familiarity with the workflow would reduce subsequent prediction times to this efficient baseline.
Conversely, the slowest completion times (70-90 minutes, n=4 participants) were recorded for participants with elementary education, less than 1 hour daily smartphone usage, no prior agricultural app experience, and older age (greater than 50 years). These users frequently paused to read instructions, asked clarifying questions, and deliberated carefully before entering values. The slowest completion (90 minutes) represented the most challenging user profile within the sample and highlighted the limits of the current interface design for users with minimal digital literacy, validating the adoption constraint (Table 12) that acknowledged digital literacy gaps as a barrier to sustained use.
Educational attainment showed strong correlation with completion times. College level or graduate participants (n=7) achieved a mean of 25.7 minutes with a range of 5-40 minutes. High school graduate participants (n=17) achieved a mean of 44.6 minutes with a range of 30-65 minutes. Elementary graduate participants (n=12) achieved a mean of 71.2 minutes with a range of 45-90 minutes. This pattern indicated that literacy and general educational background influenced both technology navigation skills and comprehension of agronomic terminology (addressing the technical skill constraint in Table 12). The nearly 2.8-fold difference between college and elementary completion times reinforced the importance of visual design and simplified interaction patterns (NFR2) for accommodating users with limited formal education, who constituted 33.3% of the UAT sample and likely represented a significant proportion of the broader rice farming population in Hagonoy.
Prior agricultural app experience also strongly predicted completion time. Participants with prior experience (n=5) achieved a mean of 33.0 minutes, while those without prior experience (n=31) achieved a mean of 52.5 minutes. Participants with prior experience (13.9% of sample) completed tasks 37% faster than first-time users, suggesting a learning curve that could be mitigated through training sessions, community demonstrations facilitated by the Promoter segment (25.0% expressing strong recommendation likelihood), or improved onboarding guidance. The Getting Started guide (Figure 29c) provided visual walkthrough, but the 37% time difference suggested that transfer learning from prior agricultural app usage (Rice Doctor, Rice Crop Manager, etc., Table 2) accelerated comprehension of interaction patterns, implying that farmers' first experience with any agricultural app created a substantial learning investment that benefited subsequent app usage.
Daily smartphone usage demonstrated a clear gradient in completion times. Participants with more than 5 hours daily usage (n=5) achieved a mean of 29.0 minutes. Those with 3-5 hours (n=7) achieved 37.9 minutes. Those with 1-3 hours (n=14) achieved 46.3 minutes. Those with less than 1 hour (n=10) achieved 73.5 minutes. This 2.5-fold difference confirmed that general digital device proficiency transferred to agricultural app usage, with extensive smartphone users completing the workflow more than twice as fast as minimal users. The finding validated the adoption constraint analysis (Table 12) that recognized limited digital literacy and variable familiarity with smartphone interface conventions as key barriers to efficient tool usage. The gradient pattern also suggested that interventions to increase general smartphone usage (e.g., through digital literacy training programs promoted by the Digital Farmers Program 103, documented in the RRL) would have spillover benefits for agricultural app adoption beyond app-specific training.
Despite the substantial variation, the median completion time of 45.0 minutes represented a reasonable one-time investment for obtaining a scientifically-validated yield prediction (test set R²=0.765, RMSE=2,286 kg) that could inform fertilizer purchasing decisions potentially worth thousands of pesos per hectare. Several farmers explicitly acknowledged this value proposition during debriefing: "Mahal ang abono, so kung makatabang ni nga mas tama ang akong bili, okay ra ang 45 minutes" (Fertilizer is expensive, so if this helps me buy the right amount, 45 minutes is fine). This comment reflected the documented economic constraint (Table 12: input subsidy shortfalls and cost sensitivity) that made optimization of fertilizer quantities particularly valuable, justifying the time investment despite moderate usability.
The interquartile range (38.8-65.0 minutes) captured the middle 50% of users and represented the typical completion time for farmers with moderate technological familiarity. This range provided a realistic expectation for deployment planning: initial training sessions should allocate approximately 60-90 minutes per participant to accommodate the learning curve, question-asking, and deliberative data entry characteristic of first-time use, while recognizing that subsequent predictions would require substantially less time as farmers became familiar with the workflow and could reference historical records (FR6).
Importantly, task completion time was expected to decrease substantially with repeated use as farmers developed familiarity with interface navigation, internalized the staged input workflow mental model (FR2), maintained records of farm data that could be reused or adapted between seasons (FR6: History feature, Figure 35), and built confidence through successful predictions that validated the tool's credibility. The History feature specifically supported this learning trajectory by allowing farmers to duplicate and modify previous predictions rather than starting from scratch each season, potentially reducing repeat-use completion times to the 5–15-minute range observed for the fastest first-time users.
The user acceptance testing with 36 rice farmers provided empirical validation of both functional value and usability challenges. The below-threshold SUS score (60.3) and high PU-PEOU gap (0.60) confirmed that while farmers recognized substantial value in yield prediction capabilities, digital literacy barriers documented in requirements planning manifested as significant usability obstacles requiring targeted interventions detailed in the recommendations. These findings informed the conclusions and recommendations presented in the following chapter.
